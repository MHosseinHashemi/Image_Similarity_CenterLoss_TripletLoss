{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHosseinHashemi/Image_Similarity_CenterLoss_TripletLoss/blob/main/Image_Simmilarity_CenterLoss_TF_v4_last_Update.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LESsrUWdiKeV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, RandomFlip, RandomRotation, Dense, Dropout, Lambda\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsP2sQmQiTo2"
      },
      "outputs": [],
      "source": [
        "(train_data, test_data, validation_data), info = tfds.load(\"oxford_flowers102\", split=['train', 'validation', 'test'], as_supervised=True, with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs5-5Z9YiUSB"
      },
      "outputs": [],
      "source": [
        "height = 224\n",
        "width = 224\n",
        "\n",
        "def preprocess_images(image, label, height, width):\n",
        "    # image = tf.image.resize_with_crop_or_pad(image, target_height=height, target_width=width)\n",
        "    image = tf.image.resize(image, [width, height])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkPAI7_qiUUS"
      },
      "outputs": [],
      "source": [
        "train_ds = train_data.map(lambda image, label: preprocess_images(image, label, height, width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_pYE9-EiUW6"
      },
      "outputs": [],
      "source": [
        "test_ds = test_data.map(lambda image, label: preprocess_images(image, label, height, width))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KktpIh3LiUZb"
      },
      "outputs": [],
      "source": [
        "def data_loader(data):\n",
        "  x = []\n",
        "  y = []\n",
        "  for img, label in tqdm(data.as_numpy_iterator()):\n",
        "    x.append(img)\n",
        "    y.append(label)\n",
        "\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpAEgn23iUbS",
        "outputId": "faa9c974-da20-4850-8c26-1b2324324a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1020it [00:03, 263.87it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, y_train = data_loader(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGHyCXxoihTz",
        "outputId": "10a4f4b9-ff5e-4e79-a623-6144f642dbef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1020it [00:03, 276.14it/s]\n"
          ]
        }
      ],
      "source": [
        "x_test, y_test = data_loader(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DmQk9fAihWB",
        "outputId": "f97350ab-1015-4040-f6dd-bdcb78fadc31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " random_flip (RandomFlip)    (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " random_rotation (RandomRot  (None, 224, 224, 3)       0         \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " keras_layer (KerasLayer)    (None, 1280)              20331360  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1311744   \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 102)               104550    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21747654 (82.96 MB)\n",
            "Trainable params: 21593782 (82.37 MB)\n",
            "Non-trainable params: 153872 (601.06 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Base Model\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2\"\n",
        "\n",
        "input_layer = Input(shape=(height, width, 3))\n",
        "x = RandomFlip()(input_layer)\n",
        "x = RandomRotation(0.3)(x)\n",
        "x = hub.KerasLayer(MODEL_URL, trainable=True)(x) # In the previous version was False\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(1024, activation=None)(x)\n",
        "x = Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)  # L2 normalize embeddings\n",
        "output_layer = Dense(102, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUEsVIwEihYl"
      },
      "outputs": [],
      "source": [
        "def batch_me(images, labels, batch_size, samples_per_class):\n",
        "  temp_dict = defaultdict(list) # A Dic of Lists to save img, label pairs as one object\n",
        "  for img, label in zip(images, labels):\n",
        "    temp_dict[label].append(img)\n",
        "\n",
        "  while True:\n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    while len(batch_x) < batch_size:\n",
        "      for category, examples in temp_dict.items():\n",
        "        # Only feed as large as the \"samples per class\"\n",
        "        # If the batch did not had enough space, feed as much as it has\n",
        "        n_samples = min(samples_per_class, (batch_size - len(batch_x)))\n",
        "        if n_samples == 0:\n",
        "          break\n",
        "        # Pick randomly from simmilar images of the same category\n",
        "        samples = random.sample(examples, k=n_samples)\n",
        "        # Add corresponding x, y values to the batch\n",
        "        batch_x.extend(samples)\n",
        "        batch_y.extend([category] * len(samples))\n",
        "\n",
        "\n",
        "    # It should be a continous operation\n",
        "    yield np.array(batch_x), np.array(batch_y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOQRKkqNwmG5"
      },
      "outputs": [],
      "source": [
        "def center_loss(feature_vector, center):\n",
        "    difference = feature_vector - center\n",
        "    loss = tf.reduce_mean(tf.reduce_sum(difference**2, axis=1))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK7pcdXVohII"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id5Jbcj7Ong9"
      },
      "outputs": [],
      "source": [
        "feature_extraction_model = Model(inputs=model.input, outputs=model.layers[-2].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE02PKJdOL0A",
        "outputId": "936a8895-acf3-4da7-d195-573b469d748c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [00:00<00:00, 490618.13it/s]\n"
          ]
        }
      ],
      "source": [
        "raw_features = {}\n",
        "class_feature_vectors = {}  # Store pre-calculated feature vectors for each class\n",
        "\n",
        "# Calculate and store class feature vectors\n",
        "for x, y in zip(x_train, y_train):\n",
        "    if y not in class_feature_vectors:\n",
        "        feature_vector = feature_extraction_model.predict(np.expand_dims(x, axis=0), verbose = 0).mean()\n",
        "        class_feature_vectors[y] = feature_vector\n",
        "\n",
        "# Calculate raw_features using class_feature_vectors\n",
        "for x, y in zip(x_train, y_train):\n",
        "    if y in raw_features:\n",
        "        new_center = feature_extraction_model.predict(np.expand_dims(x, axis=0), verbose = 0).mean()\n",
        "        raw_features[y] = [(prev + new_center) / 2 for prev in raw_features[y]]\n",
        "    else:\n",
        "        raw_features[y] = [class_feature_vectors[y]] * 1024 # 1024 is the output size of feature vectors\n",
        "\n",
        "all_features = {key: value for key, value in tqdm(raw_features.items())}\n",
        "\n",
        "# Clean up memory\n",
        "del class_feature_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy94s6HnkWx-"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UAmPnDANvNo",
        "outputId": "46178db9-69a6-4bbb-ef98-0c52503a9dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/120 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x783728e50c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x783728e50c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 -step: 1 -running loss: 4.729\n",
            "Epoch: 0 -step: 2 -running loss: 4.386\n",
            "Epoch: 0 -step: 3 -running loss: 4.166\n",
            "Epoch: 0 -step: 4 -running loss: 4.085\n",
            "Epoch: 0 -step: 5 -running loss: 3.930\n",
            "Epoch: 0 -step: 6 -running loss: 3.793\n",
            "Epoch: 0 -step: 7 -running loss: 3.686\n",
            "Epoch: 0 -step: 8 -running loss: 3.653\n",
            "Epoch: 0 -step: 9 -running loss: 3.487\n",
            "Epoch: 0 -step: 10 -running loss: 3.437\n",
            "Epoch: 0 -step: 11 -running loss: 3.325\n",
            "Epoch: 0 -step: 12 -running loss: 3.261\n",
            "Epoch: 0 -step: 13 -running loss: 3.180\n",
            "Epoch: 0 -step: 14 -running loss: 3.129\n",
            "Epoch: 0 -step: 15 -running loss: 3.073\n",
            "Epoch: 0 -step: 16 -running loss: 3.024\n",
            "Epoch: 0 -step: 17 -running loss: 2.983\n",
            "Epoch: 0 -step: 18 -running loss: 2.938\n",
            "Epoch: 0 -step: 19 -running loss: 2.896\n",
            "Epoch: 0 -step: 20 -running loss: 2.856\n",
            "Epoch: 0 -step: 21 -running loss: 2.815\n",
            "Epoch: 0 -step: 22 -running loss: 2.774\n",
            "Epoch: 0 -step: 23 -running loss: 2.731\n",
            "Epoch: 0 -step: 24 -running loss: 2.690\n",
            "Epoch: 0 -step: 25 -running loss: 2.649\n",
            "Epoch: 0 -step: 26 -running loss: 2.607\n",
            "Epoch: 0 -step: 27 -running loss: 2.565\n",
            "Epoch: 0 -step: 28 -running loss: 2.524\n",
            "Epoch: 0 -step: 29 -running loss: 2.482\n",
            "Epoch: 0 -step: 30 -running loss: 2.441\n",
            "Epoch: 0 -step: 31 -running loss: 2.399\n",
            "Epoch: 0 -step: 32 -running loss: 2.357\n",
            "Epoch: 0 -step: 33 -running loss: 2.316\n",
            "Epoch: 0 -step: 34 -running loss: 2.276\n",
            "Epoch: 0 -step: 35 -running loss: 2.235\n",
            "Epoch: 0 -step: 36 -running loss: 2.195\n",
            "Epoch: 0 -step: 37 -running loss: 2.155\n",
            "Epoch: 0 -step: 38 -running loss: 2.115\n",
            "Epoch: 0 -step: 39 -running loss: 2.076\n",
            "Epoch: 0 -step: 40 -running loss: 2.036\n",
            "Epoch: 0 -step: 41 -running loss: 1.998\n",
            "Epoch: 0 -step: 42 -running loss: 1.959\n",
            "\n",
            "Epoch 1/120 - Training Loss: 2.915 - Validation Loss: 8.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/120 [03:03<6:03:48, 183.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 0\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 1 -step: 1 -running loss: 1.921\n",
            "Epoch: 1 -step: 2 -running loss: 1.884\n",
            "Epoch: 1 -step: 3 -running loss: 1.846\n",
            "Epoch: 1 -step: 4 -running loss: 1.810\n",
            "Epoch: 1 -step: 5 -running loss: 1.773\n",
            "Epoch: 1 -step: 6 -running loss: 1.738\n",
            "Epoch: 1 -step: 7 -running loss: 1.702\n",
            "Epoch: 1 -step: 8 -running loss: 1.667\n",
            "Epoch: 1 -step: 9 -running loss: 1.633\n",
            "Epoch: 1 -step: 10 -running loss: 1.599\n",
            "Epoch: 1 -step: 11 -running loss: 1.566\n",
            "Epoch: 1 -step: 12 -running loss: 1.533\n",
            "Epoch: 1 -step: 13 -running loss: 1.501\n",
            "Epoch: 1 -step: 14 -running loss: 1.470\n",
            "Epoch: 1 -step: 15 -running loss: 1.439\n",
            "Epoch: 1 -step: 16 -running loss: 1.408\n",
            "Epoch: 1 -step: 17 -running loss: 1.378\n",
            "Epoch: 1 -step: 18 -running loss: 1.349\n",
            "Epoch: 1 -step: 19 -running loss: 1.320\n",
            "Epoch: 1 -step: 20 -running loss: 1.293\n",
            "Epoch: 1 -step: 21 -running loss: 1.265\n",
            "Epoch: 1 -step: 22 -running loss: 1.238\n",
            "Epoch: 1 -step: 23 -running loss: 1.212\n",
            "Epoch: 1 -step: 24 -running loss: 1.186\n",
            "Epoch: 1 -step: 25 -running loss: 1.161\n",
            "Epoch: 1 -step: 26 -running loss: 1.137\n",
            "Epoch: 1 -step: 27 -running loss: 1.113\n",
            "Epoch: 1 -step: 28 -running loss: 1.089\n",
            "Epoch: 1 -step: 29 -running loss: 1.067\n",
            "Epoch: 1 -step: 30 -running loss: 1.044\n",
            "Epoch: 1 -step: 31 -running loss: 1.023\n",
            "Epoch: 1 -step: 32 -running loss: 1.001\n",
            "Epoch: 1 -step: 33 -running loss: 0.981\n",
            "Epoch: 1 -step: 34 -running loss: 0.961\n",
            "Epoch: 1 -step: 35 -running loss: 0.941\n",
            "Epoch: 1 -step: 36 -running loss: 0.922\n",
            "Epoch: 1 -step: 37 -running loss: 0.904\n",
            "Epoch: 1 -step: 38 -running loss: 0.886\n",
            "Epoch: 1 -step: 39 -running loss: 0.868\n",
            "Epoch: 1 -step: 40 -running loss: 0.851\n",
            "Epoch: 1 -step: 41 -running loss: 0.834\n",
            "Epoch: 1 -step: 42 -running loss: 0.818\n",
            "\n",
            "Epoch 2/120 - Training Loss: 1.294 - Validation Loss: 9.417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/120 [04:47<4:29:22, 136.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 1\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 2 -step: 1 -running loss: 0.802\n",
            "Epoch: 2 -step: 2 -running loss: 0.787\n",
            "Epoch: 2 -step: 3 -running loss: 0.772\n",
            "Epoch: 2 -step: 4 -running loss: 0.757\n",
            "Epoch: 2 -step: 5 -running loss: 0.743\n",
            "Epoch: 2 -step: 6 -running loss: 0.729\n",
            "Epoch: 2 -step: 7 -running loss: 0.716\n",
            "Epoch: 2 -step: 8 -running loss: 0.703\n",
            "Epoch: 2 -step: 9 -running loss: 0.690\n",
            "Epoch: 2 -step: 10 -running loss: 0.678\n",
            "Epoch: 2 -step: 11 -running loss: 0.666\n",
            "Epoch: 2 -step: 12 -running loss: 0.654\n",
            "Epoch: 2 -step: 13 -running loss: 0.643\n",
            "Epoch: 2 -step: 14 -running loss: 0.632\n",
            "Epoch: 2 -step: 15 -running loss: 0.621\n",
            "Epoch: 2 -step: 16 -running loss: 0.611\n",
            "Epoch: 2 -step: 17 -running loss: 0.601\n",
            "Epoch: 2 -step: 18 -running loss: 0.591\n",
            "Epoch: 2 -step: 19 -running loss: 0.581\n",
            "Epoch: 2 -step: 20 -running loss: 0.572\n",
            "Epoch: 2 -step: 21 -running loss: 0.563\n",
            "Epoch: 2 -step: 22 -running loss: 0.554\n",
            "Epoch: 2 -step: 23 -running loss: 0.545\n",
            "Epoch: 2 -step: 24 -running loss: 0.537\n",
            "Epoch: 2 -step: 25 -running loss: 0.529\n",
            "Epoch: 2 -step: 26 -running loss: 0.521\n",
            "Epoch: 2 -step: 27 -running loss: 0.513\n",
            "Epoch: 2 -step: 28 -running loss: 0.506\n",
            "Epoch: 2 -step: 29 -running loss: 0.498\n",
            "Epoch: 2 -step: 30 -running loss: 0.491\n",
            "Epoch: 2 -step: 31 -running loss: 0.484\n",
            "Epoch: 2 -step: 32 -running loss: 0.477\n",
            "Epoch: 2 -step: 33 -running loss: 0.471\n",
            "Epoch: 2 -step: 34 -running loss: 0.464\n",
            "Epoch: 2 -step: 35 -running loss: 0.458\n",
            "Epoch: 2 -step: 36 -running loss: 0.452\n",
            "Epoch: 2 -step: 37 -running loss: 0.446\n",
            "Epoch: 2 -step: 38 -running loss: 0.440\n",
            "Epoch: 2 -step: 39 -running loss: 0.434\n",
            "Epoch: 2 -step: 40 -running loss: 0.429\n",
            "Epoch: 2 -step: 41 -running loss: 0.423\n",
            "Epoch: 2 -step: 42 -running loss: 0.418\n",
            "\n",
            "Epoch 3/120 - Training Loss: 0.576 - Validation Loss: 12.105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 3/120 [06:32<3:58:08, 122.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 2\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 3 -step: 1 -running loss: 0.413\n",
            "Epoch: 3 -step: 2 -running loss: 0.408\n",
            "Epoch: 3 -step: 3 -running loss: 0.403\n",
            "Epoch: 3 -step: 4 -running loss: 0.398\n",
            "Epoch: 3 -step: 5 -running loss: 0.394\n",
            "Epoch: 3 -step: 6 -running loss: 0.389\n",
            "Epoch: 3 -step: 7 -running loss: 0.385\n",
            "Epoch: 3 -step: 8 -running loss: 0.380\n",
            "Epoch: 3 -step: 9 -running loss: 0.376\n",
            "Epoch: 3 -step: 10 -running loss: 0.372\n",
            "Epoch: 3 -step: 11 -running loss: 0.368\n",
            "Epoch: 3 -step: 12 -running loss: 0.364\n",
            "Epoch: 3 -step: 13 -running loss: 0.360\n",
            "Epoch: 3 -step: 14 -running loss: 0.356\n",
            "Epoch: 3 -step: 15 -running loss: 0.353\n",
            "Epoch: 3 -step: 16 -running loss: 0.349\n",
            "Epoch: 3 -step: 17 -running loss: 0.345\n",
            "Epoch: 3 -step: 18 -running loss: 0.342\n",
            "Epoch: 3 -step: 19 -running loss: 0.339\n",
            "Epoch: 3 -step: 20 -running loss: 0.335\n",
            "Epoch: 3 -step: 21 -running loss: 0.332\n",
            "Epoch: 3 -step: 22 -running loss: 0.329\n",
            "Epoch: 3 -step: 23 -running loss: 0.326\n",
            "Epoch: 3 -step: 24 -running loss: 0.323\n",
            "Epoch: 3 -step: 25 -running loss: 0.320\n",
            "Epoch: 3 -step: 26 -running loss: 0.317\n",
            "Epoch: 3 -step: 27 -running loss: 0.314\n",
            "Epoch: 3 -step: 28 -running loss: 0.311\n",
            "Epoch: 3 -step: 29 -running loss: 0.308\n",
            "Epoch: 3 -step: 30 -running loss: 0.306\n",
            "Epoch: 3 -step: 31 -running loss: 0.303\n",
            "Epoch: 3 -step: 32 -running loss: 0.301\n",
            "Epoch: 3 -step: 33 -running loss: 0.298\n",
            "Epoch: 3 -step: 34 -running loss: 0.296\n",
            "Epoch: 3 -step: 35 -running loss: 0.293\n",
            "Epoch: 3 -step: 36 -running loss: 0.291\n",
            "Epoch: 3 -step: 37 -running loss: 0.288\n",
            "Epoch: 3 -step: 38 -running loss: 0.286\n",
            "Epoch: 3 -step: 39 -running loss: 0.284\n",
            "Epoch: 3 -step: 40 -running loss: 0.282\n",
            "Epoch: 3 -step: 41 -running loss: 0.280\n",
            "Epoch: 3 -step: 42 -running loss: 0.277\n",
            "\n",
            "Epoch 4/120 - Training Loss: 0.336 - Validation Loss: 17.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 4/120 [08:17<3:43:31, 115.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 3\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 4 -step: 1 -running loss: 0.275\n",
            "Epoch: 4 -step: 2 -running loss: 0.273\n",
            "Epoch: 4 -step: 3 -running loss: 0.271\n",
            "Epoch: 4 -step: 4 -running loss: 0.269\n",
            "Epoch: 4 -step: 5 -running loss: 0.267\n",
            "Epoch: 4 -step: 6 -running loss: 0.265\n",
            "Epoch: 4 -step: 7 -running loss: 0.264\n",
            "Epoch: 4 -step: 8 -running loss: 0.262\n",
            "Epoch: 4 -step: 9 -running loss: 0.260\n",
            "Epoch: 4 -step: 10 -running loss: 0.258\n",
            "Epoch: 4 -step: 11 -running loss: 0.256\n",
            "Epoch: 4 -step: 12 -running loss: 0.255\n",
            "Epoch: 4 -step: 13 -running loss: 0.253\n",
            "Epoch: 4 -step: 14 -running loss: 0.251\n",
            "Epoch: 4 -step: 15 -running loss: 0.250\n",
            "Epoch: 4 -step: 16 -running loss: 0.248\n",
            "Epoch: 4 -step: 17 -running loss: 0.247\n",
            "Epoch: 4 -step: 18 -running loss: 0.245\n",
            "Epoch: 4 -step: 19 -running loss: 0.244\n",
            "Epoch: 4 -step: 20 -running loss: 0.242\n",
            "Epoch: 4 -step: 21 -running loss: 0.241\n",
            "Epoch: 4 -step: 22 -running loss: 0.239\n",
            "Epoch: 4 -step: 23 -running loss: 0.238\n",
            "Epoch: 4 -step: 24 -running loss: 0.236\n",
            "Epoch: 4 -step: 25 -running loss: 0.235\n",
            "Epoch: 4 -step: 26 -running loss: 0.234\n",
            "Epoch: 4 -step: 27 -running loss: 0.232\n",
            "Epoch: 4 -step: 28 -running loss: 0.231\n",
            "Epoch: 4 -step: 29 -running loss: 0.230\n",
            "Epoch: 4 -step: 30 -running loss: 0.228\n",
            "Epoch: 4 -step: 31 -running loss: 0.227\n",
            "Epoch: 4 -step: 32 -running loss: 0.226\n",
            "Epoch: 4 -step: 33 -running loss: 0.225\n",
            "Epoch: 4 -step: 34 -running loss: 0.224\n",
            "Epoch: 4 -step: 35 -running loss: 0.222\n",
            "Epoch: 4 -step: 36 -running loss: 0.221\n",
            "Epoch: 4 -step: 37 -running loss: 0.220\n",
            "Epoch: 4 -step: 38 -running loss: 0.219\n",
            "Epoch: 4 -step: 39 -running loss: 0.218\n",
            "Epoch: 4 -step: 40 -running loss: 0.217\n",
            "Epoch: 4 -step: 41 -running loss: 0.216\n",
            "Epoch: 4 -step: 42 -running loss: 0.215\n",
            "\n",
            "Epoch 5/120 - Training Loss: 0.242 - Validation Loss: 24.154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 5/120 [10:02<3:33:58, 111.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 4\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 5 -step: 1 -running loss: 0.214\n",
            "Epoch: 5 -step: 2 -running loss: 0.213\n",
            "Epoch: 5 -step: 3 -running loss: 0.212\n",
            "Epoch: 5 -step: 4 -running loss: 0.211\n",
            "Epoch: 5 -step: 5 -running loss: 0.210\n",
            "Epoch: 5 -step: 6 -running loss: 0.209\n",
            "Epoch: 5 -step: 7 -running loss: 0.208\n",
            "Epoch: 5 -step: 8 -running loss: 0.207\n",
            "Epoch: 5 -step: 9 -running loss: 0.206\n",
            "Epoch: 5 -step: 10 -running loss: 0.205\n",
            "Epoch: 5 -step: 11 -running loss: 0.204\n",
            "Epoch: 5 -step: 12 -running loss: 0.203\n",
            "Epoch: 5 -step: 13 -running loss: 0.202\n",
            "Epoch: 5 -step: 14 -running loss: 0.201\n",
            "Epoch: 5 -step: 15 -running loss: 0.200\n",
            "Epoch: 5 -step: 16 -running loss: 0.200\n",
            "Epoch: 5 -step: 17 -running loss: 0.199\n",
            "Epoch: 5 -step: 18 -running loss: 0.198\n",
            "Epoch: 5 -step: 19 -running loss: 0.197\n",
            "Epoch: 5 -step: 20 -running loss: 0.196\n",
            "Epoch: 5 -step: 21 -running loss: 0.195\n",
            "Epoch: 5 -step: 22 -running loss: 0.195\n",
            "Epoch: 5 -step: 23 -running loss: 0.194\n",
            "Epoch: 5 -step: 24 -running loss: 0.193\n",
            "Epoch: 5 -step: 25 -running loss: 0.192\n",
            "Epoch: 5 -step: 26 -running loss: 0.192\n",
            "Epoch: 5 -step: 27 -running loss: 0.191\n",
            "Epoch: 5 -step: 28 -running loss: 0.190\n",
            "Epoch: 5 -step: 29 -running loss: 0.189\n",
            "Epoch: 5 -step: 30 -running loss: 0.189\n",
            "Epoch: 5 -step: 31 -running loss: 0.188\n",
            "Epoch: 5 -step: 32 -running loss: 0.187\n",
            "Epoch: 5 -step: 33 -running loss: 0.187\n",
            "Epoch: 5 -step: 34 -running loss: 0.186\n",
            "Epoch: 5 -step: 35 -running loss: 0.185\n",
            "Epoch: 5 -step: 36 -running loss: 0.185\n",
            "Epoch: 5 -step: 37 -running loss: 0.184\n",
            "Epoch: 5 -step: 38 -running loss: 0.183\n",
            "Epoch: 5 -step: 39 -running loss: 0.183\n",
            "Epoch: 5 -step: 40 -running loss: 0.182\n",
            "Epoch: 5 -step: 41 -running loss: 0.182\n",
            "Epoch: 5 -step: 42 -running loss: 0.181\n",
            "\n",
            "Epoch 6/120 - Training Loss: 0.196 - Validation Loss: 34.095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 6/120 [11:47<3:27:36, 109.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 5\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 6 -step: 1 -running loss: 0.180\n",
            "Epoch: 6 -step: 2 -running loss: 0.180\n",
            "Epoch: 6 -step: 3 -running loss: 0.179\n",
            "Epoch: 6 -step: 4 -running loss: 0.179\n",
            "Epoch: 6 -step: 5 -running loss: 0.178\n",
            "Epoch: 6 -step: 6 -running loss: 0.177\n",
            "Epoch: 6 -step: 7 -running loss: 0.177\n",
            "Epoch: 6 -step: 8 -running loss: 0.176\n",
            "Epoch: 6 -step: 9 -running loss: 0.176\n",
            "Epoch: 6 -step: 10 -running loss: 0.175\n",
            "Epoch: 6 -step: 11 -running loss: 0.175\n",
            "Epoch: 6 -step: 12 -running loss: 0.174\n",
            "Epoch: 6 -step: 13 -running loss: 0.174\n",
            "Epoch: 6 -step: 14 -running loss: 0.173\n",
            "Epoch: 6 -step: 15 -running loss: 0.173\n",
            "Epoch: 6 -step: 16 -running loss: 0.172\n",
            "Epoch: 6 -step: 17 -running loss: 0.171\n",
            "Epoch: 6 -step: 18 -running loss: 0.171\n",
            "Epoch: 6 -step: 19 -running loss: 0.171\n",
            "Epoch: 6 -step: 20 -running loss: 0.170\n",
            "Epoch: 6 -step: 21 -running loss: 0.170\n",
            "Epoch: 6 -step: 22 -running loss: 0.169\n",
            "Epoch: 6 -step: 23 -running loss: 0.169\n",
            "Epoch: 6 -step: 24 -running loss: 0.168\n",
            "Epoch: 6 -step: 25 -running loss: 0.168\n",
            "Epoch: 6 -step: 26 -running loss: 0.167\n",
            "Epoch: 6 -step: 27 -running loss: 0.167\n",
            "Epoch: 6 -step: 28 -running loss: 0.166\n",
            "Epoch: 6 -step: 29 -running loss: 0.166\n",
            "Epoch: 6 -step: 30 -running loss: 0.165\n",
            "Epoch: 6 -step: 31 -running loss: 0.165\n",
            "Epoch: 6 -step: 32 -running loss: 0.164\n",
            "Epoch: 6 -step: 33 -running loss: 0.164\n",
            "Epoch: 6 -step: 34 -running loss: 0.164\n",
            "Epoch: 6 -step: 35 -running loss: 0.163\n",
            "Epoch: 6 -step: 36 -running loss: 0.163\n",
            "Epoch: 6 -step: 37 -running loss: 0.162\n",
            "Epoch: 6 -step: 38 -running loss: 0.162\n",
            "Epoch: 6 -step: 39 -running loss: 0.162\n",
            "Epoch: 6 -step: 40 -running loss: 0.161\n",
            "Epoch: 6 -step: 41 -running loss: 0.161\n",
            "Epoch: 6 -step: 42 -running loss: 0.160\n",
            "\n",
            "Epoch 7/120 - Training Loss: 0.170 - Validation Loss: 53.051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 7/120 [13:32<3:23:16, 107.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 6\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 7 -step: 1 -running loss: 0.160\n",
            "Epoch: 7 -step: 2 -running loss: 0.160\n",
            "Epoch: 7 -step: 3 -running loss: 0.159\n",
            "Epoch: 7 -step: 4 -running loss: 0.159\n",
            "Epoch: 7 -step: 5 -running loss: 0.158\n",
            "Epoch: 7 -step: 6 -running loss: 0.158\n",
            "Epoch: 7 -step: 7 -running loss: 0.158\n",
            "Epoch: 7 -step: 8 -running loss: 0.157\n",
            "Epoch: 7 -step: 9 -running loss: 0.157\n",
            "Epoch: 7 -step: 10 -running loss: 0.157\n",
            "Epoch: 7 -step: 11 -running loss: 0.156\n",
            "Epoch: 7 -step: 12 -running loss: 0.156\n",
            "Epoch: 7 -step: 13 -running loss: 0.156\n",
            "Epoch: 7 -step: 14 -running loss: 0.155\n",
            "Epoch: 7 -step: 15 -running loss: 0.155\n",
            "Epoch: 7 -step: 16 -running loss: 0.155\n",
            "Epoch: 7 -step: 17 -running loss: 0.154\n",
            "Epoch: 7 -step: 18 -running loss: 0.154\n",
            "Epoch: 7 -step: 19 -running loss: 0.154\n",
            "Epoch: 7 -step: 20 -running loss: 0.153\n",
            "Epoch: 7 -step: 21 -running loss: 0.153\n",
            "Epoch: 7 -step: 22 -running loss: 0.153\n",
            "Epoch: 7 -step: 23 -running loss: 0.152\n",
            "Epoch: 7 -step: 24 -running loss: 0.152\n",
            "Epoch: 7 -step: 25 -running loss: 0.152\n",
            "Epoch: 7 -step: 26 -running loss: 0.151\n",
            "Epoch: 7 -step: 27 -running loss: 0.151\n",
            "Epoch: 7 -step: 28 -running loss: 0.151\n",
            "Epoch: 7 -step: 29 -running loss: 0.150\n",
            "Epoch: 7 -step: 30 -running loss: 0.150\n",
            "Epoch: 7 -step: 31 -running loss: 0.150\n",
            "Epoch: 7 -step: 32 -running loss: 0.149\n",
            "Epoch: 7 -step: 33 -running loss: 0.149\n",
            "Epoch: 7 -step: 34 -running loss: 0.149\n",
            "Epoch: 7 -step: 35 -running loss: 0.149\n",
            "Epoch: 7 -step: 36 -running loss: 0.148\n",
            "Epoch: 7 -step: 37 -running loss: 0.148\n",
            "Epoch: 7 -step: 38 -running loss: 0.148\n",
            "Epoch: 7 -step: 39 -running loss: 0.147\n",
            "Epoch: 7 -step: 40 -running loss: 0.147\n",
            "Epoch: 7 -step: 41 -running loss: 0.147\n",
            "Epoch: 7 -step: 42 -running loss: 0.147\n",
            "\n",
            "Epoch 8/120 - Training Loss: 0.153 - Validation Loss: 93.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 8/120 [15:16<3:19:24, 106.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 7\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 8 -step: 1 -running loss: 0.146\n",
            "Epoch: 8 -step: 2 -running loss: 0.146\n",
            "Epoch: 8 -step: 3 -running loss: 0.146\n",
            "Epoch: 8 -step: 4 -running loss: 0.146\n",
            "Epoch: 8 -step: 5 -running loss: 0.145\n",
            "Epoch: 8 -step: 6 -running loss: 0.145\n",
            "Epoch: 8 -step: 7 -running loss: 0.145\n",
            "Epoch: 8 -step: 8 -running loss: 0.145\n",
            "Epoch: 8 -step: 9 -running loss: 0.144\n",
            "Epoch: 8 -step: 10 -running loss: 0.144\n",
            "Epoch: 8 -step: 11 -running loss: 0.144\n",
            "Epoch: 8 -step: 12 -running loss: 0.144\n",
            "Epoch: 8 -step: 13 -running loss: 0.143\n",
            "Epoch: 8 -step: 14 -running loss: 0.143\n",
            "Epoch: 8 -step: 15 -running loss: 0.143\n",
            "Epoch: 8 -step: 16 -running loss: 0.143\n",
            "Epoch: 8 -step: 17 -running loss: 0.142\n",
            "Epoch: 8 -step: 18 -running loss: 0.142\n",
            "Epoch: 8 -step: 19 -running loss: 0.142\n",
            "Epoch: 8 -step: 20 -running loss: 0.142\n",
            "Epoch: 8 -step: 21 -running loss: 0.141\n",
            "Epoch: 8 -step: 22 -running loss: 0.141\n",
            "Epoch: 8 -step: 23 -running loss: 0.141\n",
            "Epoch: 8 -step: 24 -running loss: 0.141\n",
            "Epoch: 8 -step: 25 -running loss: 0.140\n",
            "Epoch: 8 -step: 26 -running loss: 0.140\n",
            "Epoch: 8 -step: 27 -running loss: 0.140\n",
            "Epoch: 8 -step: 28 -running loss: 0.140\n",
            "Epoch: 8 -step: 29 -running loss: 0.140\n",
            "Epoch: 8 -step: 30 -running loss: 0.139\n",
            "Epoch: 8 -step: 31 -running loss: 0.139\n",
            "Epoch: 8 -step: 32 -running loss: 0.139\n",
            "Epoch: 8 -step: 33 -running loss: 0.139\n",
            "Epoch: 8 -step: 34 -running loss: 0.138\n",
            "Epoch: 8 -step: 35 -running loss: 0.138\n",
            "Epoch: 8 -step: 36 -running loss: 0.138\n",
            "Epoch: 8 -step: 37 -running loss: 0.138\n",
            "Epoch: 8 -step: 38 -running loss: 0.138\n",
            "Epoch: 8 -step: 39 -running loss: 0.137\n",
            "Epoch: 8 -step: 40 -running loss: 0.137\n",
            "Epoch: 8 -step: 41 -running loss: 0.137\n",
            "Epoch: 8 -step: 42 -running loss: 0.137\n",
            "\n",
            "Epoch 9/120 - Training Loss: 0.141 - Validation Loss: 167.357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 9/120 [17:01<3:16:15, 106.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 8\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 9 -step: 1 -running loss: 0.137\n",
            "Epoch: 9 -step: 2 -running loss: 0.136\n",
            "Epoch: 9 -step: 3 -running loss: 0.136\n",
            "Epoch: 9 -step: 4 -running loss: 0.136\n",
            "Epoch: 9 -step: 5 -running loss: 0.136\n",
            "Epoch: 9 -step: 6 -running loss: 0.136\n",
            "Epoch: 9 -step: 7 -running loss: 0.135\n",
            "Epoch: 9 -step: 8 -running loss: 0.135\n",
            "Epoch: 9 -step: 9 -running loss: 0.135\n",
            "Epoch: 9 -step: 10 -running loss: 0.135\n",
            "Epoch: 9 -step: 11 -running loss: 0.135\n",
            "Epoch: 9 -step: 12 -running loss: 0.135\n",
            "Epoch: 9 -step: 13 -running loss: 0.134\n",
            "Epoch: 9 -step: 14 -running loss: 0.134\n",
            "Epoch: 9 -step: 15 -running loss: 0.134\n",
            "Epoch: 9 -step: 16 -running loss: 0.134\n",
            "Epoch: 9 -step: 17 -running loss: 0.134\n",
            "Epoch: 9 -step: 18 -running loss: 0.133\n",
            "Epoch: 9 -step: 19 -running loss: 0.133\n",
            "Epoch: 9 -step: 20 -running loss: 0.133\n",
            "Epoch: 9 -step: 21 -running loss: 0.133\n",
            "Epoch: 9 -step: 22 -running loss: 0.133\n",
            "Epoch: 9 -step: 23 -running loss: 0.132\n",
            "Epoch: 9 -step: 24 -running loss: 0.132\n",
            "Epoch: 9 -step: 25 -running loss: 0.132\n",
            "Epoch: 9 -step: 26 -running loss: 0.132\n",
            "Epoch: 9 -step: 27 -running loss: 0.132\n",
            "Epoch: 9 -step: 28 -running loss: 0.132\n",
            "Epoch: 9 -step: 29 -running loss: 0.131\n",
            "Epoch: 9 -step: 30 -running loss: 0.131\n",
            "Epoch: 9 -step: 31 -running loss: 0.131\n",
            "Epoch: 9 -step: 32 -running loss: 0.131\n",
            "Epoch: 9 -step: 33 -running loss: 0.131\n",
            "Epoch: 9 -step: 34 -running loss: 0.131\n",
            "Epoch: 9 -step: 35 -running loss: 0.130\n",
            "Epoch: 9 -step: 36 -running loss: 0.130\n",
            "Epoch: 9 -step: 37 -running loss: 0.130\n",
            "Epoch: 9 -step: 38 -running loss: 0.130\n",
            "Epoch: 9 -step: 39 -running loss: 0.130\n",
            "Epoch: 9 -step: 40 -running loss: 0.129\n",
            "Epoch: 9 -step: 41 -running loss: 0.130\n",
            "Epoch: 9 -step: 42 -running loss: 0.130\n",
            "\n",
            "Epoch 10/120 - Training Loss: 0.133 - Validation Loss: 154.764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 10/120 [18:46<3:14:04, 105.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 9\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 10 -step: 1 -running loss: 0.130\n",
            "Epoch: 10 -step: 2 -running loss: 0.129\n",
            "Epoch: 10 -step: 3 -running loss: 0.129\n",
            "Epoch: 10 -step: 4 -running loss: 0.129\n",
            "Epoch: 10 -step: 5 -running loss: 0.129\n",
            "Epoch: 10 -step: 6 -running loss: 0.129\n",
            "Epoch: 10 -step: 7 -running loss: 0.128\n",
            "Epoch: 10 -step: 8 -running loss: 0.128\n",
            "Epoch: 10 -step: 9 -running loss: 0.128\n",
            "Epoch: 10 -step: 10 -running loss: 0.128\n",
            "Epoch: 10 -step: 11 -running loss: 0.128\n",
            "Epoch: 10 -step: 12 -running loss: 0.128\n",
            "Epoch: 10 -step: 13 -running loss: 0.127\n",
            "Epoch: 10 -step: 14 -running loss: 0.127\n",
            "Epoch: 10 -step: 15 -running loss: 0.127\n",
            "Epoch: 10 -step: 16 -running loss: 0.127\n",
            "Epoch: 10 -step: 17 -running loss: 0.127\n",
            "Epoch: 10 -step: 18 -running loss: 0.127\n",
            "Epoch: 10 -step: 19 -running loss: 0.127\n",
            "Epoch: 10 -step: 20 -running loss: 0.126\n",
            "Epoch: 10 -step: 21 -running loss: 0.126\n",
            "Epoch: 10 -step: 22 -running loss: 0.126\n",
            "Epoch: 10 -step: 23 -running loss: 0.126\n",
            "Epoch: 10 -step: 24 -running loss: 0.126\n",
            "Epoch: 10 -step: 25 -running loss: 0.126\n",
            "Epoch: 10 -step: 26 -running loss: 0.125\n",
            "Epoch: 10 -step: 27 -running loss: 0.125\n",
            "Epoch: 10 -step: 28 -running loss: 0.125\n",
            "Epoch: 10 -step: 29 -running loss: 0.125\n",
            "Epoch: 10 -step: 30 -running loss: 0.125\n",
            "Epoch: 10 -step: 31 -running loss: 0.125\n",
            "Epoch: 10 -step: 32 -running loss: 0.125\n",
            "Epoch: 10 -step: 33 -running loss: 0.125\n",
            "Epoch: 10 -step: 34 -running loss: 0.125\n",
            "Epoch: 10 -step: 35 -running loss: 0.124\n",
            "Epoch: 10 -step: 36 -running loss: 0.124\n",
            "Epoch: 10 -step: 37 -running loss: 0.124\n",
            "Epoch: 10 -step: 38 -running loss: 0.124\n",
            "Epoch: 10 -step: 39 -running loss: 0.124\n",
            "Epoch: 10 -step: 40 -running loss: 0.124\n",
            "Epoch: 10 -step: 41 -running loss: 0.124\n",
            "Epoch: 10 -step: 42 -running loss: 0.123\n",
            "\n",
            "Epoch 11/120 - Training Loss: 0.126 - Validation Loss: 381.993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 11/120 [20:31<3:11:51, 105.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 10\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 11 -step: 1 -running loss: 0.123\n",
            "Epoch: 11 -step: 2 -running loss: 0.123\n",
            "Epoch: 11 -step: 3 -running loss: 0.123\n",
            "Epoch: 11 -step: 4 -running loss: 0.123\n",
            "Epoch: 11 -step: 5 -running loss: 0.123\n",
            "Epoch: 11 -step: 6 -running loss: 0.123\n",
            "Epoch: 11 -step: 7 -running loss: 0.123\n",
            "Epoch: 11 -step: 8 -running loss: 0.122\n",
            "Epoch: 11 -step: 9 -running loss: 0.122\n",
            "Epoch: 11 -step: 10 -running loss: 0.122\n",
            "Epoch: 11 -step: 11 -running loss: 0.122\n",
            "Epoch: 11 -step: 12 -running loss: 0.122\n",
            "Epoch: 11 -step: 13 -running loss: 0.122\n",
            "Epoch: 11 -step: 14 -running loss: 0.122\n",
            "Epoch: 11 -step: 15 -running loss: 0.122\n",
            "Epoch: 11 -step: 16 -running loss: 0.122\n",
            "Epoch: 11 -step: 17 -running loss: 0.121\n",
            "Epoch: 11 -step: 18 -running loss: 0.121\n",
            "Epoch: 11 -step: 19 -running loss: 0.121\n",
            "Epoch: 11 -step: 20 -running loss: 0.121\n",
            "Epoch: 11 -step: 21 -running loss: 0.121\n",
            "Epoch: 11 -step: 22 -running loss: 0.121\n",
            "Epoch: 11 -step: 23 -running loss: 0.120\n",
            "Epoch: 11 -step: 24 -running loss: 0.120\n",
            "Epoch: 11 -step: 25 -running loss: 0.121\n",
            "Epoch: 11 -step: 26 -running loss: 0.147\n",
            "Epoch: 11 -step: 27 -running loss: 4.447\n",
            "Epoch: 11 -step: 28 -running loss: 2.013\n",
            "Epoch: 11 -step: 29 -running loss: 1.925\n",
            "Epoch: 11 -step: 30 -running loss: 2.511\n",
            "Epoch: 11 -step: 31 -running loss: 1.832\n",
            "Epoch: 11 -step: 32 -running loss: 1.624\n",
            "Epoch: 11 -step: 33 -running loss: 1.513\n",
            "Epoch: 11 -step: 34 -running loss: 1.510\n",
            "Epoch: 11 -step: 35 -running loss: 1.517\n",
            "Epoch: 11 -step: 36 -running loss: 1.513\n",
            "Epoch: 11 -step: 37 -running loss: 1.506\n",
            "Epoch: 11 -step: 38 -running loss: 1.505\n",
            "Epoch: 11 -step: 39 -running loss: 1.504\n",
            "Epoch: 11 -step: 40 -running loss: 1.504\n",
            "Epoch: 11 -step: 41 -running loss: 4.357\n",
            "Epoch: 11 -step: 42 -running loss: 4.356\n",
            "\n",
            "Epoch 12/120 - Training Loss: 0.913 - Validation Loss: 0.110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 12/120 [22:16<3:09:24, 105.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 11\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 12 -step: 1 -running loss: 4.355\n",
            "Epoch: 12 -step: 2 -running loss: 4.353\n",
            "Epoch: 12 -step: 3 -running loss: 4.351\n",
            "Epoch: 12 -step: 4 -running loss: 4.349\n",
            "Epoch: 12 -step: 5 -running loss: 4.346\n",
            "Epoch: 12 -step: 6 -running loss: 4.343\n",
            "Epoch: 12 -step: 7 -running loss: 4.340\n",
            "Epoch: 12 -step: 8 -running loss: 4.336\n",
            "Epoch: 12 -step: 9 -running loss: 4.333\n",
            "Epoch: 12 -step: 10 -running loss: 4.329\n",
            "Epoch: 12 -step: 11 -running loss: 4.325\n",
            "Epoch: 12 -step: 12 -running loss: 4.321\n",
            "Epoch: 12 -step: 13 -running loss: 4.317\n",
            "Epoch: 12 -step: 14 -running loss: 4.313\n",
            "Epoch: 12 -step: 15 -running loss: 4.308\n",
            "Epoch: 12 -step: 16 -running loss: 4.304\n",
            "Epoch: 12 -step: 17 -running loss: 4.300\n",
            "Epoch: 12 -step: 18 -running loss: 4.295\n",
            "Epoch: 12 -step: 19 -running loss: 4.291\n",
            "Epoch: 12 -step: 20 -running loss: 4.286\n",
            "Epoch: 12 -step: 21 -running loss: 4.282\n",
            "Epoch: 12 -step: 22 -running loss: 4.277\n",
            "Epoch: 12 -step: 23 -running loss: 4.273\n",
            "Epoch: 12 -step: 24 -running loss: 4.268\n",
            "Epoch: 12 -step: 25 -running loss: 4.264\n",
            "Epoch: 12 -step: 26 -running loss: 4.259\n",
            "Epoch: 12 -step: 27 -running loss: 4.255\n",
            "Epoch: 12 -step: 28 -running loss: 4.250\n",
            "Epoch: 12 -step: 29 -running loss: 4.246\n",
            "Epoch: 12 -step: 30 -running loss: 4.241\n",
            "Epoch: 12 -step: 31 -running loss: 4.237\n",
            "Epoch: 12 -step: 32 -running loss: 4.232\n",
            "Epoch: 12 -step: 33 -running loss: 4.228\n",
            "Epoch: 12 -step: 34 -running loss: 4.223\n",
            "Epoch: 12 -step: 35 -running loss: 4.219\n",
            "Epoch: 12 -step: 36 -running loss: 4.215\n",
            "Epoch: 12 -step: 37 -running loss: 4.210\n",
            "Epoch: 12 -step: 38 -running loss: 4.206\n",
            "Epoch: 12 -step: 39 -running loss: 4.202\n",
            "Epoch: 12 -step: 40 -running loss: 4.197\n",
            "Epoch: 12 -step: 41 -running loss: 4.193\n",
            "Epoch: 12 -step: 42 -running loss: 4.189\n",
            "\n",
            "Epoch 13/120 - Training Loss: 4.278 - Validation Loss: 0.111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 13/120 [24:00<3:06:59, 104.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 12\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 13 -step: 1 -running loss: 4.184\n",
            "Epoch: 13 -step: 2 -running loss: 4.180\n",
            "Epoch: 13 -step: 3 -running loss: 4.176\n",
            "Epoch: 13 -step: 4 -running loss: 4.172\n",
            "Epoch: 13 -step: 5 -running loss: 4.167\n",
            "Epoch: 13 -step: 6 -running loss: 4.163\n",
            "Epoch: 13 -step: 7 -running loss: 4.159\n",
            "Epoch: 13 -step: 8 -running loss: 4.155\n",
            "Epoch: 13 -step: 9 -running loss: 4.151\n",
            "Epoch: 13 -step: 10 -running loss: 4.147\n",
            "Epoch: 13 -step: 11 -running loss: 4.143\n",
            "Epoch: 13 -step: 12 -running loss: 4.139\n",
            "Epoch: 13 -step: 13 -running loss: 4.135\n",
            "Epoch: 13 -step: 14 -running loss: 4.131\n",
            "Epoch: 13 -step: 15 -running loss: 4.127\n",
            "Epoch: 13 -step: 16 -running loss: 4.123\n",
            "Epoch: 13 -step: 17 -running loss: 4.119\n",
            "Epoch: 13 -step: 18 -running loss: 4.115\n",
            "Epoch: 13 -step: 19 -running loss: 4.111\n",
            "Epoch: 13 -step: 20 -running loss: 4.107\n",
            "Epoch: 13 -step: 21 -running loss: 4.103\n",
            "Epoch: 13 -step: 22 -running loss: 4.099\n",
            "Epoch: 13 -step: 23 -running loss: 4.095\n",
            "Epoch: 13 -step: 24 -running loss: 4.091\n",
            "Epoch: 13 -step: 25 -running loss: 4.088\n",
            "Epoch: 13 -step: 26 -running loss: 4.084\n",
            "Epoch: 13 -step: 27 -running loss: 4.080\n",
            "Epoch: 13 -step: 28 -running loss: 4.076\n",
            "Epoch: 13 -step: 29 -running loss: 4.072\n",
            "Epoch: 13 -step: 30 -running loss: 4.069\n",
            "Epoch: 13 -step: 31 -running loss: 4.065\n",
            "Epoch: 13 -step: 32 -running loss: 4.061\n",
            "Epoch: 13 -step: 33 -running loss: 4.058\n",
            "Epoch: 13 -step: 34 -running loss: 4.054\n",
            "Epoch: 13 -step: 35 -running loss: 4.050\n",
            "Epoch: 13 -step: 36 -running loss: 4.047\n",
            "Epoch: 13 -step: 37 -running loss: 4.043\n",
            "Epoch: 13 -step: 38 -running loss: 4.039\n",
            "Epoch: 13 -step: 39 -running loss: 4.036\n",
            "Epoch: 13 -step: 40 -running loss: 4.032\n",
            "Epoch: 13 -step: 41 -running loss: 4.028\n",
            "Epoch: 13 -step: 42 -running loss: 4.025\n",
            "\n",
            "Epoch 14/120 - Training Loss: 4.102 - Validation Loss: 0.111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 14/120 [25:43<3:04:38, 104.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 13\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 14 -step: 1 -running loss: 4.021\n",
            "Epoch: 14 -step: 2 -running loss: 4.018\n",
            "Epoch: 14 -step: 3 -running loss: 4.014\n",
            "Epoch: 14 -step: 4 -running loss: 4.011\n",
            "Epoch: 14 -step: 5 -running loss: 4.007\n",
            "Epoch: 14 -step: 6 -running loss: 4.004\n",
            "Epoch: 14 -step: 7 -running loss: 4.000\n",
            "Epoch: 14 -step: 8 -running loss: 3.997\n",
            "Epoch: 14 -step: 9 -running loss: 3.993\n",
            "Epoch: 14 -step: 10 -running loss: 3.990\n",
            "Epoch: 14 -step: 11 -running loss: 3.986\n",
            "Epoch: 14 -step: 12 -running loss: 3.983\n",
            "Epoch: 14 -step: 13 -running loss: 3.979\n",
            "Epoch: 14 -step: 14 -running loss: 3.976\n",
            "Epoch: 14 -step: 15 -running loss: 3.972\n",
            "Epoch: 14 -step: 16 -running loss: 3.969\n",
            "Epoch: 14 -step: 17 -running loss: 3.966\n",
            "Epoch: 14 -step: 18 -running loss: 3.962\n",
            "Epoch: 14 -step: 19 -running loss: 3.959\n",
            "Epoch: 14 -step: 20 -running loss: 3.956\n",
            "Epoch: 14 -step: 21 -running loss: 3.952\n",
            "Epoch: 14 -step: 22 -running loss: 3.949\n",
            "Epoch: 14 -step: 23 -running loss: 3.946\n",
            "Epoch: 14 -step: 24 -running loss: 3.942\n",
            "Epoch: 14 -step: 25 -running loss: 3.939\n",
            "Epoch: 14 -step: 26 -running loss: 3.936\n",
            "Epoch: 14 -step: 27 -running loss: 3.932\n",
            "Epoch: 14 -step: 28 -running loss: 3.929\n",
            "Epoch: 14 -step: 29 -running loss: 3.926\n",
            "Epoch: 14 -step: 30 -running loss: 3.923\n",
            "Epoch: 14 -step: 31 -running loss: 3.919\n",
            "Epoch: 14 -step: 32 -running loss: 3.916\n",
            "Epoch: 14 -step: 33 -running loss: 3.913\n",
            "Epoch: 14 -step: 34 -running loss: 3.910\n",
            "Epoch: 14 -step: 35 -running loss: 3.906\n",
            "Epoch: 14 -step: 36 -running loss: 3.903\n",
            "Epoch: 14 -step: 37 -running loss: 3.900\n",
            "Epoch: 14 -step: 38 -running loss: 3.897\n",
            "Epoch: 14 -step: 39 -running loss: 3.894\n",
            "Epoch: 14 -step: 40 -running loss: 3.891\n",
            "Epoch: 14 -step: 41 -running loss: 3.887\n",
            "Epoch: 14 -step: 42 -running loss: 3.884\n",
            "\n",
            "Epoch 15/120 - Training Loss: 3.951 - Validation Loss: 0.111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 15/120 [27:27<3:02:32, 104.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 14\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 15 -step: 1 -running loss: 3.881\n",
            "Epoch: 15 -step: 2 -running loss: 3.878\n",
            "Epoch: 15 -step: 3 -running loss: 3.875\n",
            "Epoch: 15 -step: 4 -running loss: 3.872\n",
            "Epoch: 15 -step: 5 -running loss: 3.869\n",
            "Epoch: 15 -step: 6 -running loss: 3.865\n",
            "Epoch: 15 -step: 7 -running loss: 3.862\n",
            "Epoch: 15 -step: 8 -running loss: 3.859\n",
            "Epoch: 15 -step: 9 -running loss: 3.856\n",
            "Epoch: 15 -step: 10 -running loss: 3.853\n",
            "Epoch: 15 -step: 11 -running loss: 3.850\n",
            "Epoch: 15 -step: 12 -running loss: 3.847\n",
            "Epoch: 15 -step: 13 -running loss: 3.844\n",
            "Epoch: 15 -step: 14 -running loss: 3.841\n",
            "Epoch: 15 -step: 15 -running loss: 3.838\n",
            "Epoch: 15 -step: 16 -running loss: 3.835\n",
            "Epoch: 15 -step: 17 -running loss: 3.832\n",
            "Epoch: 15 -step: 18 -running loss: 3.829\n",
            "Epoch: 15 -step: 19 -running loss: 3.826\n",
            "Epoch: 15 -step: 20 -running loss: 3.823\n",
            "Epoch: 15 -step: 21 -running loss: 3.820\n",
            "Epoch: 15 -step: 22 -running loss: 3.817\n",
            "Epoch: 15 -step: 23 -running loss: 3.814\n",
            "Epoch: 15 -step: 24 -running loss: 3.811\n",
            "Epoch: 15 -step: 25 -running loss: 3.808\n",
            "Epoch: 15 -step: 26 -running loss: 3.805\n",
            "Epoch: 15 -step: 27 -running loss: 3.802\n",
            "Epoch: 15 -step: 28 -running loss: 3.799\n",
            "Epoch: 15 -step: 29 -running loss: 3.796\n",
            "Epoch: 15 -step: 30 -running loss: 3.793\n",
            "Epoch: 15 -step: 31 -running loss: 3.790\n",
            "Epoch: 15 -step: 32 -running loss: 3.787\n",
            "Epoch: 15 -step: 33 -running loss: 3.784\n",
            "Epoch: 15 -step: 34 -running loss: 3.782\n",
            "Epoch: 15 -step: 35 -running loss: 3.779\n",
            "Epoch: 15 -step: 36 -running loss: 3.776\n",
            "Epoch: 15 -step: 37 -running loss: 3.773\n",
            "Epoch: 15 -step: 38 -running loss: 3.770\n",
            "Epoch: 15 -step: 39 -running loss: 3.767\n",
            "Epoch: 15 -step: 40 -running loss: 3.764\n",
            "Epoch: 15 -step: 41 -running loss: 3.761\n",
            "Epoch: 15 -step: 42 -running loss: 3.758\n",
            "\n",
            "Epoch 16/120 - Training Loss: 3.819 - Validation Loss: 0.112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 16/120 [29:11<3:00:33, 104.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 15\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 16 -step: 1 -running loss: 3.756\n",
            "Epoch: 16 -step: 2 -running loss: 3.753\n",
            "Epoch: 16 -step: 3 -running loss: 3.750\n",
            "Epoch: 16 -step: 4 -running loss: 3.747\n",
            "Epoch: 16 -step: 5 -running loss: 3.744\n",
            "Epoch: 16 -step: 6 -running loss: 3.741\n",
            "Epoch: 16 -step: 7 -running loss: 3.739\n",
            "Epoch: 16 -step: 8 -running loss: 3.736\n",
            "Epoch: 16 -step: 9 -running loss: 3.733\n",
            "Epoch: 16 -step: 10 -running loss: 3.730\n",
            "Epoch: 16 -step: 11 -running loss: 3.727\n",
            "Epoch: 16 -step: 12 -running loss: 3.725\n",
            "Epoch: 16 -step: 13 -running loss: 3.722\n",
            "Epoch: 16 -step: 14 -running loss: 3.719\n",
            "Epoch: 16 -step: 15 -running loss: 3.716\n",
            "Epoch: 16 -step: 16 -running loss: 3.714\n",
            "Epoch: 16 -step: 17 -running loss: 3.711\n",
            "Epoch: 16 -step: 18 -running loss: 3.708\n",
            "Epoch: 16 -step: 19 -running loss: 3.705\n",
            "Epoch: 16 -step: 20 -running loss: 3.703\n",
            "Epoch: 16 -step: 21 -running loss: 3.700\n",
            "Epoch: 16 -step: 22 -running loss: 3.697\n",
            "Epoch: 16 -step: 23 -running loss: 3.694\n",
            "Epoch: 16 -step: 24 -running loss: 3.692\n",
            "Epoch: 16 -step: 25 -running loss: 3.689\n",
            "Epoch: 16 -step: 26 -running loss: 3.686\n",
            "Epoch: 16 -step: 27 -running loss: 3.683\n",
            "Epoch: 16 -step: 28 -running loss: 3.681\n",
            "Epoch: 16 -step: 29 -running loss: 3.678\n",
            "Epoch: 16 -step: 30 -running loss: 3.675\n",
            "Epoch: 16 -step: 31 -running loss: 3.673\n",
            "Epoch: 16 -step: 32 -running loss: 3.670\n",
            "Epoch: 16 -step: 33 -running loss: 3.667\n",
            "Epoch: 16 -step: 34 -running loss: 3.665\n",
            "Epoch: 16 -step: 35 -running loss: 3.662\n",
            "Epoch: 16 -step: 36 -running loss: 3.659\n",
            "Epoch: 16 -step: 37 -running loss: 3.657\n",
            "Epoch: 16 -step: 38 -running loss: 3.654\n",
            "Epoch: 16 -step: 39 -running loss: 3.651\n",
            "Epoch: 16 -step: 40 -running loss: 3.649\n",
            "Epoch: 16 -step: 41 -running loss: 3.646\n",
            "Epoch: 16 -step: 42 -running loss: 3.643\n",
            "\n",
            "Epoch 17/120 - Training Loss: 3.699 - Validation Loss: 0.112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 17/120 [30:56<2:59:19, 104.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 16\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 17 -step: 1 -running loss: 3.641\n",
            "Epoch: 17 -step: 2 -running loss: 3.638\n",
            "Epoch: 17 -step: 3 -running loss: 3.635\n",
            "Epoch: 17 -step: 4 -running loss: 3.633\n",
            "Epoch: 17 -step: 5 -running loss: 3.630\n",
            "Epoch: 17 -step: 6 -running loss: 3.628\n",
            "Epoch: 17 -step: 7 -running loss: 3.625\n",
            "Epoch: 17 -step: 8 -running loss: 3.622\n",
            "Epoch: 17 -step: 9 -running loss: 3.620\n",
            "Epoch: 17 -step: 10 -running loss: 3.617\n",
            "Epoch: 17 -step: 11 -running loss: 3.615\n",
            "Epoch: 17 -step: 12 -running loss: 3.612\n",
            "Epoch: 17 -step: 13 -running loss: 3.609\n",
            "Epoch: 17 -step: 14 -running loss: 3.607\n",
            "Epoch: 17 -step: 15 -running loss: 3.604\n",
            "Epoch: 17 -step: 16 -running loss: 3.602\n",
            "Epoch: 17 -step: 17 -running loss: 3.599\n",
            "Epoch: 17 -step: 18 -running loss: 3.597\n",
            "Epoch: 17 -step: 19 -running loss: 3.594\n",
            "Epoch: 17 -step: 20 -running loss: 3.592\n",
            "Epoch: 17 -step: 21 -running loss: 3.589\n",
            "Epoch: 17 -step: 22 -running loss: 3.586\n",
            "Epoch: 17 -step: 23 -running loss: 3.584\n",
            "Epoch: 17 -step: 24 -running loss: 3.581\n",
            "Epoch: 17 -step: 25 -running loss: 3.579\n",
            "Epoch: 17 -step: 26 -running loss: 3.576\n",
            "Epoch: 17 -step: 27 -running loss: 3.574\n",
            "Epoch: 17 -step: 28 -running loss: 3.571\n",
            "Epoch: 17 -step: 29 -running loss: 3.569\n",
            "Epoch: 17 -step: 30 -running loss: 3.566\n",
            "Epoch: 17 -step: 31 -running loss: 3.564\n",
            "Epoch: 17 -step: 32 -running loss: 3.561\n",
            "Epoch: 17 -step: 33 -running loss: 3.559\n",
            "Epoch: 17 -step: 34 -running loss: 3.556\n",
            "Epoch: 17 -step: 35 -running loss: 3.554\n",
            "Epoch: 17 -step: 36 -running loss: 3.551\n",
            "Epoch: 17 -step: 37 -running loss: 3.549\n",
            "Epoch: 17 -step: 38 -running loss: 3.546\n",
            "Epoch: 17 -step: 39 -running loss: 3.544\n",
            "Epoch: 17 -step: 40 -running loss: 3.541\n",
            "Epoch: 17 -step: 41 -running loss: 3.539\n",
            "Epoch: 17 -step: 42 -running loss: 3.536\n",
            "\n",
            "Epoch 18/120 - Training Loss: 3.588 - Validation Loss: 0.112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 18/120 [32:41<2:57:37, 104.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 17\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 18 -step: 1 -running loss: 3.534\n",
            "Epoch: 18 -step: 2 -running loss: 3.532\n",
            "Epoch: 18 -step: 3 -running loss: 3.529\n",
            "Epoch: 18 -step: 4 -running loss: 3.527\n",
            "Epoch: 18 -step: 5 -running loss: 3.524\n",
            "Epoch: 18 -step: 6 -running loss: 3.522\n",
            "Epoch: 18 -step: 7 -running loss: 3.519\n",
            "Epoch: 18 -step: 8 -running loss: 3.517\n",
            "Epoch: 18 -step: 9 -running loss: 3.514\n",
            "Epoch: 18 -step: 10 -running loss: 3.512\n",
            "Epoch: 18 -step: 11 -running loss: 3.510\n",
            "Epoch: 18 -step: 12 -running loss: 3.507\n",
            "Epoch: 18 -step: 13 -running loss: 3.505\n",
            "Epoch: 18 -step: 14 -running loss: 3.502\n",
            "Epoch: 18 -step: 15 -running loss: 3.500\n",
            "Epoch: 18 -step: 16 -running loss: 3.498\n",
            "Epoch: 18 -step: 17 -running loss: 3.495\n",
            "Epoch: 18 -step: 18 -running loss: 3.493\n",
            "Epoch: 18 -step: 19 -running loss: 3.490\n",
            "Epoch: 18 -step: 20 -running loss: 3.488\n",
            "Epoch: 18 -step: 21 -running loss: 3.486\n",
            "Epoch: 18 -step: 22 -running loss: 3.483\n",
            "Epoch: 18 -step: 23 -running loss: 3.481\n",
            "Epoch: 18 -step: 24 -running loss: 3.478\n",
            "Epoch: 18 -step: 25 -running loss: 3.476\n",
            "Epoch: 18 -step: 26 -running loss: 3.474\n",
            "Epoch: 18 -step: 27 -running loss: 3.471\n",
            "Epoch: 18 -step: 28 -running loss: 3.469\n",
            "Epoch: 18 -step: 29 -running loss: 3.467\n",
            "Epoch: 18 -step: 30 -running loss: 3.464\n",
            "Epoch: 18 -step: 31 -running loss: 3.462\n",
            "Epoch: 18 -step: 32 -running loss: 3.460\n",
            "Epoch: 18 -step: 33 -running loss: 3.457\n",
            "Epoch: 18 -step: 34 -running loss: 3.455\n",
            "Epoch: 18 -step: 35 -running loss: 3.452\n",
            "Epoch: 18 -step: 36 -running loss: 3.450\n",
            "Epoch: 18 -step: 37 -running loss: 3.448\n",
            "Epoch: 18 -step: 38 -running loss: 3.445\n",
            "Epoch: 18 -step: 39 -running loss: 3.443\n",
            "Epoch: 18 -step: 40 -running loss: 3.441\n",
            "Epoch: 18 -step: 41 -running loss: 3.439\n",
            "Epoch: 18 -step: 42 -running loss: 3.436\n",
            "\n",
            "Epoch 19/120 - Training Loss: 3.485 - Validation Loss: 0.112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 19/120 [34:42<3:04:26, 109.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 18\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 19 -step: 1 -running loss: 3.434\n",
            "Epoch: 19 -step: 2 -running loss: 3.432\n",
            "Epoch: 19 -step: 3 -running loss: 3.429\n",
            "Epoch: 19 -step: 4 -running loss: 3.427\n",
            "Epoch: 19 -step: 5 -running loss: 3.425\n",
            "Epoch: 19 -step: 6 -running loss: 3.422\n",
            "Epoch: 19 -step: 7 -running loss: 3.420\n",
            "Epoch: 19 -step: 8 -running loss: 3.418\n",
            "Epoch: 19 -step: 9 -running loss: 3.415\n",
            "Epoch: 19 -step: 10 -running loss: 3.413\n",
            "Epoch: 19 -step: 11 -running loss: 3.411\n",
            "Epoch: 19 -step: 12 -running loss: 3.409\n",
            "Epoch: 19 -step: 13 -running loss: 3.406\n",
            "Epoch: 19 -step: 14 -running loss: 3.404\n",
            "Epoch: 19 -step: 15 -running loss: 3.402\n",
            "Epoch: 19 -step: 16 -running loss: 3.400\n",
            "Epoch: 19 -step: 17 -running loss: 3.397\n",
            "Epoch: 19 -step: 18 -running loss: 3.395\n",
            "Epoch: 19 -step: 19 -running loss: 3.393\n",
            "Epoch: 19 -step: 20 -running loss: 3.390\n",
            "Epoch: 19 -step: 21 -running loss: 3.388\n",
            "Epoch: 19 -step: 22 -running loss: 3.386\n",
            "Epoch: 19 -step: 23 -running loss: 3.384\n",
            "Epoch: 19 -step: 24 -running loss: 3.381\n",
            "Epoch: 19 -step: 25 -running loss: 3.379\n",
            "Epoch: 19 -step: 26 -running loss: 3.377\n",
            "Epoch: 19 -step: 27 -running loss: 3.375\n",
            "Epoch: 19 -step: 28 -running loss: 3.373\n",
            "Epoch: 19 -step: 29 -running loss: 3.370\n",
            "Epoch: 19 -step: 30 -running loss: 3.368\n",
            "Epoch: 19 -step: 31 -running loss: 3.366\n",
            "Epoch: 19 -step: 32 -running loss: 3.364\n",
            "Epoch: 19 -step: 33 -running loss: 3.361\n",
            "Epoch: 19 -step: 34 -running loss: 3.359\n",
            "Epoch: 19 -step: 35 -running loss: 3.357\n",
            "Epoch: 19 -step: 36 -running loss: 3.355\n",
            "Epoch: 19 -step: 37 -running loss: 3.353\n",
            "Epoch: 19 -step: 38 -running loss: 3.350\n",
            "Epoch: 19 -step: 39 -running loss: 3.348\n",
            "Epoch: 19 -step: 40 -running loss: 3.346\n",
            "Epoch: 19 -step: 41 -running loss: 3.344\n",
            "Epoch: 19 -step: 42 -running loss: 3.342\n",
            "\n",
            "Epoch 20/120 - Training Loss: 3.387 - Validation Loss: 0.113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 20/120 [36:29<3:01:20, 108.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 19\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 20 -step: 1 -running loss: 3.339\n",
            "Epoch: 20 -step: 2 -running loss: 3.337\n",
            "Epoch: 20 -step: 3 -running loss: 3.335\n",
            "Epoch: 20 -step: 4 -running loss: 3.333\n",
            "Epoch: 20 -step: 5 -running loss: 3.331\n",
            "Epoch: 20 -step: 6 -running loss: 3.328\n",
            "Epoch: 20 -step: 7 -running loss: 3.326\n",
            "Epoch: 20 -step: 8 -running loss: 3.324\n",
            "Epoch: 20 -step: 9 -running loss: 3.322\n",
            "Epoch: 20 -step: 10 -running loss: 3.320\n",
            "Epoch: 20 -step: 11 -running loss: 3.318\n",
            "Epoch: 20 -step: 12 -running loss: 3.315\n",
            "Epoch: 20 -step: 13 -running loss: 3.313\n",
            "Epoch: 20 -step: 14 -running loss: 3.311\n",
            "Epoch: 20 -step: 15 -running loss: 3.309\n",
            "Epoch: 20 -step: 16 -running loss: 3.307\n",
            "Epoch: 20 -step: 17 -running loss: 3.305\n",
            "Epoch: 20 -step: 18 -running loss: 3.303\n",
            "Epoch: 20 -step: 19 -running loss: 3.300\n",
            "Epoch: 20 -step: 20 -running loss: 3.298\n",
            "Epoch: 20 -step: 21 -running loss: 3.296\n",
            "Epoch: 20 -step: 22 -running loss: 3.294\n",
            "Epoch: 20 -step: 23 -running loss: 3.292\n",
            "Epoch: 20 -step: 24 -running loss: 3.290\n",
            "Epoch: 20 -step: 25 -running loss: 3.288\n",
            "Epoch: 20 -step: 26 -running loss: 3.285\n",
            "Epoch: 20 -step: 27 -running loss: 3.283\n",
            "Epoch: 20 -step: 28 -running loss: 3.281\n",
            "Epoch: 20 -step: 29 -running loss: 3.279\n",
            "Epoch: 20 -step: 30 -running loss: 3.277\n",
            "Epoch: 20 -step: 31 -running loss: 3.275\n",
            "Epoch: 20 -step: 32 -running loss: 3.273\n",
            "Epoch: 20 -step: 33 -running loss: 3.271\n",
            "Epoch: 20 -step: 34 -running loss: 3.269\n",
            "Epoch: 20 -step: 35 -running loss: 3.266\n",
            "Epoch: 20 -step: 36 -running loss: 3.264\n",
            "Epoch: 20 -step: 37 -running loss: 3.262\n",
            "Epoch: 20 -step: 38 -running loss: 3.260\n",
            "Epoch: 20 -step: 39 -running loss: 3.258\n",
            "Epoch: 20 -step: 40 -running loss: 3.256\n",
            "Epoch: 20 -step: 41 -running loss: 3.254\n",
            "Epoch: 20 -step: 42 -running loss: 3.252\n",
            "\n",
            "Epoch 21/120 - Training Loss: 3.295 - Validation Loss: 0.113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 21/120 [38:15<2:57:57, 107.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 20\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 21 -step: 1 -running loss: 3.250\n",
            "Epoch: 21 -step: 2 -running loss: 3.248\n",
            "Epoch: 21 -step: 3 -running loss: 3.246\n",
            "Epoch: 21 -step: 4 -running loss: 3.244\n",
            "Epoch: 21 -step: 5 -running loss: 3.241\n",
            "Epoch: 21 -step: 6 -running loss: 3.239\n",
            "Epoch: 21 -step: 7 -running loss: 3.237\n",
            "Epoch: 21 -step: 8 -running loss: 3.235\n",
            "Epoch: 21 -step: 9 -running loss: 3.233\n",
            "Epoch: 21 -step: 10 -running loss: 3.231\n",
            "Epoch: 21 -step: 11 -running loss: 3.229\n",
            "Epoch: 21 -step: 12 -running loss: 3.227\n",
            "Epoch: 21 -step: 13 -running loss: 3.225\n",
            "Epoch: 21 -step: 14 -running loss: 3.223\n",
            "Epoch: 21 -step: 15 -running loss: 3.221\n",
            "Epoch: 21 -step: 16 -running loss: 3.219\n",
            "Epoch: 21 -step: 17 -running loss: 3.217\n",
            "Epoch: 21 -step: 18 -running loss: 3.215\n",
            "Epoch: 21 -step: 19 -running loss: 3.213\n",
            "Epoch: 21 -step: 20 -running loss: 3.211\n",
            "Epoch: 21 -step: 21 -running loss: 3.209\n",
            "Epoch: 21 -step: 22 -running loss: 3.207\n",
            "Epoch: 21 -step: 23 -running loss: 3.205\n",
            "Epoch: 21 -step: 24 -running loss: 3.203\n",
            "Epoch: 21 -step: 25 -running loss: 3.201\n",
            "Epoch: 21 -step: 26 -running loss: 3.198\n",
            "Epoch: 21 -step: 27 -running loss: 3.196\n",
            "Epoch: 21 -step: 28 -running loss: 3.194\n",
            "Epoch: 21 -step: 29 -running loss: 3.192\n",
            "Epoch: 21 -step: 30 -running loss: 3.190\n",
            "Epoch: 21 -step: 31 -running loss: 3.188\n",
            "Epoch: 21 -step: 32 -running loss: 3.186\n",
            "Epoch: 21 -step: 33 -running loss: 3.184\n",
            "Epoch: 21 -step: 34 -running loss: 3.182\n",
            "Epoch: 21 -step: 35 -running loss: 3.180\n",
            "Epoch: 21 -step: 36 -running loss: 3.178\n",
            "Epoch: 21 -step: 37 -running loss: 3.176\n",
            "Epoch: 21 -step: 38 -running loss: 3.174\n",
            "Epoch: 21 -step: 39 -running loss: 3.172\n",
            "Epoch: 21 -step: 40 -running loss: 3.170\n",
            "Epoch: 21 -step: 41 -running loss: 3.168\n",
            "Epoch: 21 -step: 42 -running loss: 3.166\n",
            "\n",
            "Epoch 22/120 - Training Loss: 3.208 - Validation Loss: 0.114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 22/120 [39:59<2:54:36, 106.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 21\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 22 -step: 1 -running loss: 3.164\n",
            "Epoch: 22 -step: 2 -running loss: 3.163\n",
            "Epoch: 22 -step: 3 -running loss: 3.161\n",
            "Epoch: 22 -step: 4 -running loss: 3.159\n",
            "Epoch: 22 -step: 5 -running loss: 3.157\n",
            "Epoch: 22 -step: 6 -running loss: 3.155\n",
            "Epoch: 22 -step: 7 -running loss: 3.153\n",
            "Epoch: 22 -step: 8 -running loss: 3.151\n",
            "Epoch: 22 -step: 9 -running loss: 3.149\n",
            "Epoch: 22 -step: 10 -running loss: 3.147\n",
            "Epoch: 22 -step: 11 -running loss: 3.145\n",
            "Epoch: 22 -step: 12 -running loss: 3.143\n",
            "Epoch: 22 -step: 13 -running loss: 3.141\n",
            "Epoch: 22 -step: 14 -running loss: 3.139\n",
            "Epoch: 22 -step: 15 -running loss: 3.137\n",
            "Epoch: 22 -step: 16 -running loss: 3.135\n",
            "Epoch: 22 -step: 17 -running loss: 3.133\n",
            "Epoch: 22 -step: 18 -running loss: 3.131\n",
            "Epoch: 22 -step: 19 -running loss: 3.129\n",
            "Epoch: 22 -step: 20 -running loss: 3.127\n",
            "Epoch: 22 -step: 21 -running loss: 3.125\n",
            "Epoch: 22 -step: 22 -running loss: 3.123\n",
            "Epoch: 22 -step: 23 -running loss: 3.121\n",
            "Epoch: 22 -step: 24 -running loss: 3.120\n",
            "Epoch: 22 -step: 25 -running loss: 3.118\n",
            "Epoch: 22 -step: 26 -running loss: 3.116\n",
            "Epoch: 22 -step: 27 -running loss: 3.114\n",
            "Epoch: 22 -step: 28 -running loss: 3.112\n",
            "Epoch: 22 -step: 29 -running loss: 3.110\n",
            "Epoch: 22 -step: 30 -running loss: 3.108\n",
            "Epoch: 22 -step: 31 -running loss: 3.106\n",
            "Epoch: 22 -step: 32 -running loss: 3.104\n",
            "Epoch: 22 -step: 33 -running loss: 3.102\n",
            "Epoch: 22 -step: 34 -running loss: 3.100\n",
            "Epoch: 22 -step: 35 -running loss: 3.098\n",
            "Epoch: 22 -step: 36 -running loss: 3.097\n",
            "Epoch: 22 -step: 37 -running loss: 3.095\n",
            "Epoch: 22 -step: 38 -running loss: 3.093\n",
            "Epoch: 22 -step: 39 -running loss: 3.091\n",
            "Epoch: 22 -step: 40 -running loss: 3.089\n",
            "Epoch: 22 -step: 41 -running loss: 3.087\n",
            "Epoch: 22 -step: 42 -running loss: 3.085\n",
            "\n",
            "Epoch 23/120 - Training Loss: 3.125 - Validation Loss: 0.114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 23/120 [41:44<2:51:37, 106.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 22\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 23 -step: 1 -running loss: 3.083\n",
            "Epoch: 23 -step: 2 -running loss: 3.081\n",
            "Epoch: 23 -step: 3 -running loss: 3.079\n",
            "Epoch: 23 -step: 4 -running loss: 3.078\n",
            "Epoch: 23 -step: 5 -running loss: 3.076\n",
            "Epoch: 23 -step: 6 -running loss: 3.074\n",
            "Epoch: 23 -step: 7 -running loss: 3.072\n",
            "Epoch: 23 -step: 8 -running loss: 3.070\n",
            "Epoch: 23 -step: 9 -running loss: 3.068\n",
            "Epoch: 23 -step: 10 -running loss: 3.066\n",
            "Epoch: 23 -step: 11 -running loss: 3.064\n",
            "Epoch: 23 -step: 12 -running loss: 3.063\n",
            "Epoch: 23 -step: 13 -running loss: 3.061\n",
            "Epoch: 23 -step: 14 -running loss: 3.059\n",
            "Epoch: 23 -step: 15 -running loss: 3.057\n",
            "Epoch: 23 -step: 16 -running loss: 3.055\n",
            "Epoch: 23 -step: 17 -running loss: 3.053\n",
            "Epoch: 23 -step: 18 -running loss: 3.051\n",
            "Epoch: 23 -step: 19 -running loss: 3.050\n",
            "Epoch: 23 -step: 20 -running loss: 3.048\n",
            "Epoch: 23 -step: 21 -running loss: 3.046\n",
            "Epoch: 23 -step: 22 -running loss: 3.044\n",
            "Epoch: 23 -step: 23 -running loss: 3.042\n",
            "Epoch: 23 -step: 24 -running loss: 3.040\n",
            "Epoch: 23 -step: 25 -running loss: 3.038\n",
            "Epoch: 23 -step: 26 -running loss: 3.037\n",
            "Epoch: 23 -step: 27 -running loss: 3.035\n",
            "Epoch: 23 -step: 28 -running loss: 3.033\n",
            "Epoch: 23 -step: 29 -running loss: 3.031\n",
            "Epoch: 23 -step: 30 -running loss: 3.029\n",
            "Epoch: 23 -step: 31 -running loss: 3.027\n",
            "Epoch: 23 -step: 32 -running loss: 3.026\n",
            "Epoch: 23 -step: 33 -running loss: 3.024\n",
            "Epoch: 23 -step: 34 -running loss: 3.022\n",
            "Epoch: 23 -step: 35 -running loss: 3.020\n",
            "Epoch: 23 -step: 36 -running loss: 3.018\n",
            "Epoch: 23 -step: 37 -running loss: 3.017\n",
            "Epoch: 23 -step: 38 -running loss: 3.015\n",
            "Epoch: 23 -step: 39 -running loss: 3.013\n",
            "Epoch: 23 -step: 40 -running loss: 3.011\n",
            "Epoch: 23 -step: 41 -running loss: 3.009\n",
            "Epoch: 23 -step: 42 -running loss: 3.007\n",
            "\n",
            "Epoch 24/120 - Training Loss: 3.045 - Validation Loss: 0.114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 24/120 [43:28<2:49:06, 105.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 23\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 24 -step: 1 -running loss: 3.006\n",
            "Epoch: 24 -step: 2 -running loss: 3.004\n",
            "Epoch: 24 -step: 3 -running loss: 3.002\n",
            "Epoch: 24 -step: 4 -running loss: 3.000\n",
            "Epoch: 24 -step: 5 -running loss: 2.998\n",
            "Epoch: 24 -step: 6 -running loss: 2.997\n",
            "Epoch: 24 -step: 7 -running loss: 2.995\n",
            "Epoch: 24 -step: 8 -running loss: 2.993\n",
            "Epoch: 24 -step: 9 -running loss: 2.991\n",
            "Epoch: 24 -step: 10 -running loss: 2.990\n",
            "Epoch: 24 -step: 11 -running loss: 2.988\n",
            "Epoch: 24 -step: 12 -running loss: 2.986\n",
            "Epoch: 24 -step: 13 -running loss: 2.984\n",
            "Epoch: 24 -step: 14 -running loss: 2.982\n",
            "Epoch: 24 -step: 15 -running loss: 2.981\n",
            "Epoch: 24 -step: 16 -running loss: 2.979\n",
            "Epoch: 24 -step: 17 -running loss: 2.977\n",
            "Epoch: 24 -step: 18 -running loss: 2.975\n",
            "Epoch: 24 -step: 19 -running loss: 2.973\n",
            "Epoch: 24 -step: 20 -running loss: 2.972\n",
            "Epoch: 24 -step: 21 -running loss: 2.970\n",
            "Epoch: 24 -step: 22 -running loss: 2.968\n",
            "Epoch: 24 -step: 23 -running loss: 2.966\n",
            "Epoch: 24 -step: 24 -running loss: 2.965\n",
            "Epoch: 24 -step: 25 -running loss: 2.963\n",
            "Epoch: 24 -step: 26 -running loss: 2.961\n",
            "Epoch: 24 -step: 27 -running loss: 2.959\n",
            "Epoch: 24 -step: 28 -running loss: 2.958\n",
            "Epoch: 24 -step: 29 -running loss: 2.956\n",
            "Epoch: 24 -step: 30 -running loss: 2.954\n",
            "Epoch: 24 -step: 31 -running loss: 2.952\n",
            "Epoch: 24 -step: 32 -running loss: 2.951\n",
            "Epoch: 24 -step: 33 -running loss: 2.949\n",
            "Epoch: 24 -step: 34 -running loss: 2.947\n",
            "Epoch: 24 -step: 35 -running loss: 2.945\n",
            "Epoch: 24 -step: 36 -running loss: 2.944\n",
            "Epoch: 24 -step: 37 -running loss: 2.942\n",
            "Epoch: 24 -step: 38 -running loss: 2.940\n",
            "Epoch: 24 -step: 39 -running loss: 2.938\n",
            "Epoch: 24 -step: 40 -running loss: 2.937\n",
            "Epoch: 24 -step: 41 -running loss: 2.935\n",
            "Epoch: 24 -step: 42 -running loss: 2.933\n",
            "\n",
            "Epoch 25/120 - Training Loss: 2.969 - Validation Loss: 0.115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 25/120 [45:13<2:46:52, 105.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 24\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 25 -step: 1 -running loss: 2.932\n",
            "Epoch: 25 -step: 2 -running loss: 2.930\n",
            "Epoch: 25 -step: 3 -running loss: 2.928\n",
            "Epoch: 25 -step: 4 -running loss: 2.926\n",
            "Epoch: 25 -step: 5 -running loss: 2.925\n",
            "Epoch: 25 -step: 6 -running loss: 2.923\n",
            "Epoch: 25 -step: 7 -running loss: 2.921\n",
            "Epoch: 25 -step: 8 -running loss: 2.920\n",
            "Epoch: 25 -step: 9 -running loss: 2.918\n",
            "Epoch: 25 -step: 10 -running loss: 2.916\n",
            "Epoch: 25 -step: 11 -running loss: 2.914\n",
            "Epoch: 25 -step: 12 -running loss: 2.913\n",
            "Epoch: 25 -step: 13 -running loss: 2.911\n",
            "Epoch: 25 -step: 14 -running loss: 2.909\n",
            "Epoch: 25 -step: 15 -running loss: 2.908\n",
            "Epoch: 25 -step: 16 -running loss: 2.906\n",
            "Epoch: 25 -step: 17 -running loss: 2.904\n",
            "Epoch: 25 -step: 18 -running loss: 2.903\n",
            "Epoch: 25 -step: 19 -running loss: 2.901\n",
            "Epoch: 25 -step: 20 -running loss: 2.899\n",
            "Epoch: 25 -step: 21 -running loss: 2.897\n",
            "Epoch: 25 -step: 22 -running loss: 2.896\n",
            "Epoch: 25 -step: 23 -running loss: 2.894\n",
            "Epoch: 25 -step: 24 -running loss: 2.892\n",
            "Epoch: 25 -step: 25 -running loss: 2.891\n",
            "Epoch: 25 -step: 26 -running loss: 2.889\n",
            "Epoch: 25 -step: 27 -running loss: 2.887\n",
            "Epoch: 25 -step: 28 -running loss: 2.886\n",
            "Epoch: 25 -step: 29 -running loss: 2.884\n",
            "Epoch: 25 -step: 30 -running loss: 2.882\n",
            "Epoch: 25 -step: 31 -running loss: 2.881\n",
            "Epoch: 25 -step: 32 -running loss: 2.879\n",
            "Epoch: 25 -step: 33 -running loss: 2.877\n",
            "Epoch: 25 -step: 34 -running loss: 2.876\n",
            "Epoch: 25 -step: 35 -running loss: 2.874\n",
            "Epoch: 25 -step: 36 -running loss: 2.872\n",
            "Epoch: 25 -step: 37 -running loss: 2.871\n",
            "Epoch: 25 -step: 38 -running loss: 2.869\n",
            "Epoch: 25 -step: 39 -running loss: 2.867\n",
            "Epoch: 25 -step: 40 -running loss: 2.866\n",
            "Epoch: 25 -step: 41 -running loss: 2.864\n",
            "Epoch: 25 -step: 42 -running loss: 2.862\n",
            "\n",
            "Epoch 26/120 - Training Loss: 2.897 - Validation Loss: 0.115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 26/120 [46:58<2:45:00, 105.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 25\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 26 -step: 1 -running loss: 2.861\n",
            "Epoch: 26 -step: 2 -running loss: 2.859\n",
            "Epoch: 26 -step: 3 -running loss: 2.857\n",
            "Epoch: 26 -step: 4 -running loss: 2.856\n",
            "Epoch: 26 -step: 5 -running loss: 2.854\n",
            "Epoch: 26 -step: 6 -running loss: 2.853\n",
            "Epoch: 26 -step: 7 -running loss: 2.851\n",
            "Epoch: 26 -step: 8 -running loss: 2.849\n",
            "Epoch: 26 -step: 9 -running loss: 2.848\n",
            "Epoch: 26 -step: 10 -running loss: 2.846\n",
            "Epoch: 26 -step: 11 -running loss: 2.844\n",
            "Epoch: 26 -step: 12 -running loss: 2.843\n",
            "Epoch: 26 -step: 13 -running loss: 2.841\n",
            "Epoch: 26 -step: 14 -running loss: 2.839\n",
            "Epoch: 26 -step: 15 -running loss: 2.838\n",
            "Epoch: 26 -step: 16 -running loss: 2.836\n",
            "Epoch: 26 -step: 17 -running loss: 2.835\n",
            "Epoch: 26 -step: 18 -running loss: 2.833\n",
            "Epoch: 26 -step: 19 -running loss: 2.831\n",
            "Epoch: 26 -step: 20 -running loss: 2.830\n",
            "Epoch: 26 -step: 21 -running loss: 2.828\n",
            "Epoch: 26 -step: 22 -running loss: 2.827\n",
            "Epoch: 26 -step: 23 -running loss: 2.825\n",
            "Epoch: 26 -step: 24 -running loss: 2.823\n",
            "Epoch: 26 -step: 25 -running loss: 2.822\n",
            "Epoch: 26 -step: 26 -running loss: 2.820\n",
            "Epoch: 26 -step: 27 -running loss: 2.818\n",
            "Epoch: 26 -step: 28 -running loss: 2.817\n",
            "Epoch: 26 -step: 29 -running loss: 2.815\n",
            "Epoch: 26 -step: 30 -running loss: 2.814\n",
            "Epoch: 26 -step: 31 -running loss: 2.812\n",
            "Epoch: 26 -step: 32 -running loss: 2.810\n",
            "Epoch: 26 -step: 33 -running loss: 2.809\n",
            "Epoch: 26 -step: 34 -running loss: 2.807\n",
            "Epoch: 26 -step: 35 -running loss: 2.806\n",
            "Epoch: 26 -step: 36 -running loss: 2.804\n",
            "Epoch: 26 -step: 37 -running loss: 2.803\n",
            "Epoch: 26 -step: 38 -running loss: 2.801\n",
            "Epoch: 26 -step: 39 -running loss: 2.799\n",
            "Epoch: 26 -step: 40 -running loss: 2.798\n",
            "Epoch: 26 -step: 41 -running loss: 2.796\n",
            "Epoch: 26 -step: 42 -running loss: 2.795\n",
            "\n",
            "Epoch 27/120 - Training Loss: 2.827 - Validation Loss: 0.116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 27/120 [48:43<2:42:53, 105.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 26\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 27 -step: 1 -running loss: 2.793\n",
            "Epoch: 27 -step: 2 -running loss: 2.791\n",
            "Epoch: 27 -step: 3 -running loss: 2.790\n",
            "Epoch: 27 -step: 4 -running loss: 2.788\n",
            "Epoch: 27 -step: 5 -running loss: 2.787\n",
            "Epoch: 27 -step: 6 -running loss: 2.785\n",
            "Epoch: 27 -step: 7 -running loss: 2.784\n",
            "Epoch: 27 -step: 8 -running loss: 2.782\n",
            "Epoch: 27 -step: 9 -running loss: 2.781\n",
            "Epoch: 27 -step: 10 -running loss: 2.779\n",
            "Epoch: 27 -step: 11 -running loss: 2.777\n",
            "Epoch: 27 -step: 12 -running loss: 2.776\n",
            "Epoch: 27 -step: 13 -running loss: 2.774\n",
            "Epoch: 27 -step: 14 -running loss: 2.773\n",
            "Epoch: 27 -step: 15 -running loss: 2.771\n",
            "Epoch: 27 -step: 16 -running loss: 2.770\n",
            "Epoch: 27 -step: 17 -running loss: 2.768\n",
            "Epoch: 27 -step: 18 -running loss: 2.767\n",
            "Epoch: 27 -step: 19 -running loss: 2.765\n",
            "Epoch: 27 -step: 20 -running loss: 2.763\n",
            "Epoch: 27 -step: 21 -running loss: 2.762\n",
            "Epoch: 27 -step: 22 -running loss: 2.760\n",
            "Epoch: 27 -step: 23 -running loss: 2.759\n",
            "Epoch: 27 -step: 24 -running loss: 2.757\n",
            "Epoch: 27 -step: 25 -running loss: 2.756\n",
            "Epoch: 27 -step: 26 -running loss: 2.754\n",
            "Epoch: 27 -step: 27 -running loss: 2.753\n",
            "Epoch: 27 -step: 28 -running loss: 2.751\n",
            "Epoch: 27 -step: 29 -running loss: 2.750\n",
            "Epoch: 27 -step: 30 -running loss: 2.748\n",
            "Epoch: 27 -step: 31 -running loss: 2.747\n",
            "Epoch: 27 -step: 32 -running loss: 2.745\n",
            "Epoch: 27 -step: 33 -running loss: 2.743\n",
            "Epoch: 27 -step: 34 -running loss: 2.742\n",
            "Epoch: 27 -step: 35 -running loss: 2.740\n",
            "Epoch: 27 -step: 36 -running loss: 2.739\n",
            "Epoch: 27 -step: 37 -running loss: 2.737\n",
            "Epoch: 27 -step: 38 -running loss: 2.736\n",
            "Epoch: 27 -step: 39 -running loss: 2.734\n",
            "Epoch: 27 -step: 40 -running loss: 2.733\n",
            "Epoch: 27 -step: 41 -running loss: 2.731\n",
            "Epoch: 27 -step: 42 -running loss: 2.730\n",
            "\n",
            "Epoch 28/120 - Training Loss: 2.761 - Validation Loss: 0.116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 28/120 [50:27<2:40:43, 104.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 27\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 28 -step: 1 -running loss: 2.728\n",
            "Epoch: 28 -step: 2 -running loss: 2.727\n",
            "Epoch: 28 -step: 3 -running loss: 2.725\n",
            "Epoch: 28 -step: 4 -running loss: 2.724\n",
            "Epoch: 28 -step: 5 -running loss: 2.722\n",
            "Epoch: 28 -step: 6 -running loss: 2.721\n",
            "Epoch: 28 -step: 7 -running loss: 2.719\n",
            "Epoch: 28 -step: 8 -running loss: 2.718\n",
            "Epoch: 28 -step: 9 -running loss: 2.716\n",
            "Epoch: 28 -step: 10 -running loss: 2.715\n",
            "Epoch: 28 -step: 11 -running loss: 2.713\n",
            "Epoch: 28 -step: 12 -running loss: 2.712\n",
            "Epoch: 28 -step: 13 -running loss: 2.710\n",
            "Epoch: 28 -step: 14 -running loss: 2.709\n",
            "Epoch: 28 -step: 15 -running loss: 2.707\n",
            "Epoch: 28 -step: 16 -running loss: 2.706\n",
            "Epoch: 28 -step: 17 -running loss: 2.704\n",
            "Epoch: 28 -step: 18 -running loss: 2.703\n",
            "Epoch: 28 -step: 19 -running loss: 2.702\n",
            "Epoch: 28 -step: 20 -running loss: 2.700\n",
            "Epoch: 28 -step: 21 -running loss: 2.699\n",
            "Epoch: 28 -step: 22 -running loss: 2.697\n",
            "Epoch: 28 -step: 23 -running loss: 2.696\n",
            "Epoch: 28 -step: 24 -running loss: 2.694\n",
            "Epoch: 28 -step: 25 -running loss: 2.693\n",
            "Epoch: 28 -step: 26 -running loss: 2.691\n",
            "Epoch: 28 -step: 27 -running loss: 2.690\n",
            "Epoch: 28 -step: 28 -running loss: 2.688\n",
            "Epoch: 28 -step: 29 -running loss: 2.687\n",
            "Epoch: 28 -step: 30 -running loss: 2.685\n",
            "Epoch: 28 -step: 31 -running loss: 2.684\n",
            "Epoch: 28 -step: 32 -running loss: 2.682\n",
            "Epoch: 28 -step: 33 -running loss: 2.681\n",
            "Epoch: 28 -step: 34 -running loss: 2.680\n",
            "Epoch: 28 -step: 35 -running loss: 2.678\n",
            "Epoch: 28 -step: 36 -running loss: 2.677\n",
            "Epoch: 28 -step: 37 -running loss: 2.675\n",
            "Epoch: 28 -step: 38 -running loss: 2.674\n",
            "Epoch: 28 -step: 39 -running loss: 2.672\n",
            "Epoch: 28 -step: 40 -running loss: 2.671\n",
            "Epoch: 28 -step: 41 -running loss: 2.669\n",
            "Epoch: 28 -step: 42 -running loss: 2.668\n",
            "\n",
            "Epoch 29/120 - Training Loss: 2.698 - Validation Loss: 0.117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 29/120 [52:12<2:39:07, 104.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 28\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 29 -step: 1 -running loss: 2.667\n",
            "Epoch: 29 -step: 2 -running loss: 2.665\n",
            "Epoch: 29 -step: 3 -running loss: 2.664\n",
            "Epoch: 29 -step: 4 -running loss: 2.662\n",
            "Epoch: 29 -step: 5 -running loss: 2.661\n",
            "Epoch: 29 -step: 6 -running loss: 2.659\n",
            "Epoch: 29 -step: 7 -running loss: 2.658\n",
            "Epoch: 29 -step: 8 -running loss: 2.656\n",
            "Epoch: 29 -step: 9 -running loss: 2.655\n",
            "Epoch: 29 -step: 10 -running loss: 2.654\n",
            "Epoch: 29 -step: 11 -running loss: 2.652\n",
            "Epoch: 29 -step: 12 -running loss: 2.651\n",
            "Epoch: 29 -step: 13 -running loss: 2.649\n",
            "Epoch: 29 -step: 14 -running loss: 2.648\n",
            "Epoch: 29 -step: 15 -running loss: 2.647\n",
            "Epoch: 29 -step: 16 -running loss: 2.645\n",
            "Epoch: 29 -step: 17 -running loss: 2.644\n",
            "Epoch: 29 -step: 18 -running loss: 2.642\n",
            "Epoch: 29 -step: 19 -running loss: 2.641\n",
            "Epoch: 29 -step: 20 -running loss: 2.639\n",
            "Epoch: 29 -step: 21 -running loss: 2.638\n",
            "Epoch: 29 -step: 22 -running loss: 2.637\n",
            "Epoch: 29 -step: 23 -running loss: 2.635\n",
            "Epoch: 29 -step: 24 -running loss: 2.634\n",
            "Epoch: 29 -step: 25 -running loss: 2.632\n",
            "Epoch: 29 -step: 26 -running loss: 2.631\n",
            "Epoch: 29 -step: 27 -running loss: 2.630\n",
            "Epoch: 29 -step: 28 -running loss: 2.628\n",
            "Epoch: 29 -step: 29 -running loss: 2.627\n",
            "Epoch: 29 -step: 30 -running loss: 2.625\n",
            "Epoch: 29 -step: 31 -running loss: 2.624\n",
            "Epoch: 29 -step: 32 -running loss: 2.623\n",
            "Epoch: 29 -step: 33 -running loss: 2.621\n",
            "Epoch: 29 -step: 34 -running loss: 2.620\n",
            "Epoch: 29 -step: 35 -running loss: 2.619\n",
            "Epoch: 29 -step: 36 -running loss: 2.617\n",
            "Epoch: 29 -step: 37 -running loss: 2.616\n",
            "Epoch: 29 -step: 38 -running loss: 2.614\n",
            "Epoch: 29 -step: 39 -running loss: 2.613\n",
            "Epoch: 29 -step: 40 -running loss: 2.612\n",
            "Epoch: 29 -step: 41 -running loss: 2.610\n",
            "Epoch: 29 -step: 42 -running loss: 2.609\n",
            "\n",
            "Epoch 30/120 - Training Loss: 2.637 - Validation Loss: 0.118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 30/120 [53:57<2:37:14, 104.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 29\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 30 -step: 1 -running loss: 2.607\n",
            "Epoch: 30 -step: 2 -running loss: 2.606\n",
            "Epoch: 30 -step: 3 -running loss: 2.605\n",
            "Epoch: 30 -step: 4 -running loss: 2.603\n",
            "Epoch: 30 -step: 5 -running loss: 2.602\n",
            "Epoch: 30 -step: 6 -running loss: 2.601\n",
            "Epoch: 30 -step: 7 -running loss: 2.599\n",
            "Epoch: 30 -step: 8 -running loss: 2.598\n",
            "Epoch: 30 -step: 9 -running loss: 2.597\n",
            "Epoch: 30 -step: 10 -running loss: 2.595\n",
            "Epoch: 30 -step: 11 -running loss: 2.594\n",
            "Epoch: 30 -step: 12 -running loss: 2.592\n",
            "Epoch: 30 -step: 13 -running loss: 2.591\n",
            "Epoch: 30 -step: 14 -running loss: 2.590\n",
            "Epoch: 30 -step: 15 -running loss: 2.588\n",
            "Epoch: 30 -step: 16 -running loss: 2.587\n",
            "Epoch: 30 -step: 17 -running loss: 2.586\n",
            "Epoch: 30 -step: 18 -running loss: 2.584\n",
            "Epoch: 30 -step: 19 -running loss: 2.583\n",
            "Epoch: 30 -step: 20 -running loss: 2.582\n",
            "Epoch: 30 -step: 21 -running loss: 2.580\n",
            "Epoch: 30 -step: 22 -running loss: 2.579\n",
            "Epoch: 30 -step: 23 -running loss: 2.578\n",
            "Epoch: 30 -step: 24 -running loss: 2.576\n",
            "Epoch: 30 -step: 25 -running loss: 2.575\n",
            "Epoch: 30 -step: 26 -running loss: 2.574\n",
            "Epoch: 30 -step: 27 -running loss: 2.572\n",
            "Epoch: 30 -step: 28 -running loss: 2.571\n",
            "Epoch: 30 -step: 29 -running loss: 2.570\n",
            "Epoch: 30 -step: 30 -running loss: 2.568\n",
            "Epoch: 30 -step: 31 -running loss: 2.567\n",
            "Epoch: 30 -step: 32 -running loss: 2.566\n",
            "Epoch: 30 -step: 33 -running loss: 2.564\n",
            "Epoch: 30 -step: 34 -running loss: 2.563\n",
            "Epoch: 30 -step: 35 -running loss: 2.562\n",
            "Epoch: 30 -step: 36 -running loss: 2.560\n",
            "Epoch: 30 -step: 37 -running loss: 2.559\n",
            "Epoch: 30 -step: 38 -running loss: 2.558\n",
            "Epoch: 30 -step: 39 -running loss: 2.556\n",
            "Epoch: 30 -step: 40 -running loss: 2.555\n",
            "Epoch: 30 -step: 41 -running loss: 2.554\n",
            "Epoch: 30 -step: 42 -running loss: 2.552\n",
            "\n",
            "Epoch 31/120 - Training Loss: 2.580 - Validation Loss: 0.118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 31/120 [55:42<2:35:28, 104.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 30\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 31 -step: 1 -running loss: 2.551\n",
            "Epoch: 31 -step: 2 -running loss: 2.550\n",
            "Epoch: 31 -step: 3 -running loss: 2.548\n",
            "Epoch: 31 -step: 4 -running loss: 2.547\n",
            "Epoch: 31 -step: 5 -running loss: 2.546\n",
            "Epoch: 31 -step: 6 -running loss: 2.545\n",
            "Epoch: 31 -step: 7 -running loss: 2.543\n",
            "Epoch: 31 -step: 8 -running loss: 2.542\n",
            "Epoch: 31 -step: 9 -running loss: 2.541\n",
            "Epoch: 31 -step: 10 -running loss: 2.539\n",
            "Epoch: 31 -step: 11 -running loss: 2.538\n",
            "Epoch: 31 -step: 12 -running loss: 2.537\n",
            "Epoch: 31 -step: 13 -running loss: 2.535\n",
            "Epoch: 31 -step: 14 -running loss: 2.534\n",
            "Epoch: 31 -step: 15 -running loss: 2.533\n",
            "Epoch: 31 -step: 16 -running loss: 2.532\n",
            "Epoch: 31 -step: 17 -running loss: 2.530\n",
            "Epoch: 31 -step: 18 -running loss: 2.529\n",
            "Epoch: 31 -step: 19 -running loss: 2.528\n",
            "Epoch: 31 -step: 20 -running loss: 2.526\n",
            "Epoch: 31 -step: 21 -running loss: 2.525\n",
            "Epoch: 31 -step: 22 -running loss: 2.524\n",
            "Epoch: 31 -step: 23 -running loss: 2.523\n",
            "Epoch: 31 -step: 24 -running loss: 2.521\n",
            "Epoch: 31 -step: 25 -running loss: 2.520\n",
            "Epoch: 31 -step: 26 -running loss: 2.519\n",
            "Epoch: 31 -step: 27 -running loss: 2.517\n",
            "Epoch: 31 -step: 28 -running loss: 2.516\n",
            "Epoch: 31 -step: 29 -running loss: 2.515\n",
            "Epoch: 31 -step: 30 -running loss: 2.514\n",
            "Epoch: 31 -step: 31 -running loss: 2.512\n",
            "Epoch: 31 -step: 32 -running loss: 2.511\n",
            "Epoch: 31 -step: 33 -running loss: 2.510\n",
            "Epoch: 31 -step: 34 -running loss: 2.509\n",
            "Epoch: 31 -step: 35 -running loss: 2.507\n",
            "Epoch: 31 -step: 36 -running loss: 2.506\n",
            "Epoch: 31 -step: 37 -running loss: 2.505\n",
            "Epoch: 31 -step: 38 -running loss: 2.504\n",
            "Epoch: 31 -step: 39 -running loss: 2.502\n",
            "Epoch: 31 -step: 40 -running loss: 2.501\n",
            "Epoch: 31 -step: 41 -running loss: 2.500\n",
            "Epoch: 31 -step: 42 -running loss: 2.499\n",
            "\n",
            "Epoch 32/120 - Training Loss: 2.525 - Validation Loss: 0.119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 32/120 [57:26<2:33:24, 104.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 31\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 32 -step: 1 -running loss: 2.497\n",
            "Epoch: 32 -step: 2 -running loss: 2.496\n",
            "Epoch: 32 -step: 3 -running loss: 2.495\n",
            "Epoch: 32 -step: 4 -running loss: 2.494\n",
            "Epoch: 32 -step: 5 -running loss: 2.492\n",
            "Epoch: 32 -step: 6 -running loss: 2.491\n",
            "Epoch: 32 -step: 7 -running loss: 2.490\n",
            "Epoch: 32 -step: 8 -running loss: 2.489\n",
            "Epoch: 32 -step: 9 -running loss: 2.487\n",
            "Epoch: 32 -step: 10 -running loss: 2.486\n",
            "Epoch: 32 -step: 11 -running loss: 2.485\n",
            "Epoch: 32 -step: 12 -running loss: 2.484\n",
            "Epoch: 32 -step: 13 -running loss: 2.482\n",
            "Epoch: 32 -step: 14 -running loss: 2.481\n",
            "Epoch: 32 -step: 15 -running loss: 2.480\n",
            "Epoch: 32 -step: 16 -running loss: 2.479\n",
            "Epoch: 32 -step: 17 -running loss: 2.477\n",
            "Epoch: 32 -step: 18 -running loss: 2.476\n",
            "Epoch: 32 -step: 19 -running loss: 2.475\n",
            "Epoch: 32 -step: 20 -running loss: 2.474\n",
            "Epoch: 32 -step: 21 -running loss: 2.473\n",
            "Epoch: 32 -step: 22 -running loss: 2.471\n",
            "Epoch: 32 -step: 23 -running loss: 2.470\n",
            "Epoch: 32 -step: 24 -running loss: 2.469\n",
            "Epoch: 32 -step: 25 -running loss: 2.468\n",
            "Epoch: 32 -step: 26 -running loss: 2.466\n",
            "Epoch: 32 -step: 27 -running loss: 2.465\n",
            "Epoch: 32 -step: 28 -running loss: 2.464\n",
            "Epoch: 32 -step: 29 -running loss: 2.463\n",
            "Epoch: 32 -step: 30 -running loss: 2.462\n",
            "Epoch: 32 -step: 31 -running loss: 2.460\n",
            "Epoch: 32 -step: 32 -running loss: 2.459\n",
            "Epoch: 32 -step: 33 -running loss: 2.458\n",
            "Epoch: 32 -step: 34 -running loss: 2.457\n",
            "Epoch: 32 -step: 35 -running loss: 2.456\n",
            "Epoch: 32 -step: 36 -running loss: 2.454\n",
            "Epoch: 32 -step: 37 -running loss: 2.453\n",
            "Epoch: 32 -step: 38 -running loss: 2.452\n",
            "Epoch: 32 -step: 39 -running loss: 2.451\n",
            "Epoch: 32 -step: 40 -running loss: 2.450\n",
            "Epoch: 32 -step: 41 -running loss: 2.448\n",
            "Epoch: 32 -step: 42 -running loss: 2.447\n",
            "\n",
            "Epoch 33/120 - Training Loss: 2.472 - Validation Loss: 0.119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 33/120 [59:10<2:31:21, 104.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 32\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 33 -step: 1 -running loss: 2.446\n",
            "Epoch: 33 -step: 2 -running loss: 2.445\n",
            "Epoch: 33 -step: 3 -running loss: 2.444\n",
            "Epoch: 33 -step: 4 -running loss: 2.442\n",
            "Epoch: 33 -step: 5 -running loss: 2.441\n",
            "Epoch: 33 -step: 6 -running loss: 2.440\n",
            "Epoch: 33 -step: 7 -running loss: 2.439\n",
            "Epoch: 33 -step: 8 -running loss: 2.438\n",
            "Epoch: 33 -step: 9 -running loss: 2.436\n",
            "Epoch: 33 -step: 10 -running loss: 2.435\n",
            "Epoch: 33 -step: 11 -running loss: 2.434\n",
            "Epoch: 33 -step: 12 -running loss: 2.433\n",
            "Epoch: 33 -step: 13 -running loss: 2.432\n",
            "Epoch: 33 -step: 14 -running loss: 2.431\n",
            "Epoch: 33 -step: 15 -running loss: 2.429\n",
            "Epoch: 33 -step: 16 -running loss: 2.428\n",
            "Epoch: 33 -step: 17 -running loss: 2.427\n",
            "Epoch: 33 -step: 18 -running loss: 2.426\n",
            "Epoch: 33 -step: 19 -running loss: 2.425\n",
            "Epoch: 33 -step: 20 -running loss: 2.424\n",
            "Epoch: 33 -step: 21 -running loss: 2.422\n",
            "Epoch: 33 -step: 22 -running loss: 2.421\n",
            "Epoch: 33 -step: 23 -running loss: 2.420\n",
            "Epoch: 33 -step: 24 -running loss: 2.419\n",
            "Epoch: 33 -step: 25 -running loss: 2.418\n",
            "Epoch: 33 -step: 26 -running loss: 2.417\n",
            "Epoch: 33 -step: 27 -running loss: 2.415\n",
            "Epoch: 33 -step: 28 -running loss: 2.414\n",
            "Epoch: 33 -step: 29 -running loss: 2.413\n",
            "Epoch: 33 -step: 30 -running loss: 2.412\n",
            "Epoch: 33 -step: 31 -running loss: 2.411\n",
            "Epoch: 33 -step: 32 -running loss: 2.410\n",
            "Epoch: 33 -step: 33 -running loss: 2.408\n",
            "Epoch: 33 -step: 34 -running loss: 2.407\n",
            "Epoch: 33 -step: 35 -running loss: 2.406\n",
            "Epoch: 33 -step: 36 -running loss: 2.405\n",
            "Epoch: 33 -step: 37 -running loss: 2.404\n",
            "Epoch: 33 -step: 38 -running loss: 2.403\n",
            "Epoch: 33 -step: 39 -running loss: 2.402\n",
            "Epoch: 33 -step: 40 -running loss: 2.400\n",
            "Epoch: 33 -step: 41 -running loss: 2.399\n",
            "Epoch: 33 -step: 42 -running loss: 2.398\n",
            "\n",
            "Epoch 34/120 - Training Loss: 2.422 - Validation Loss: 0.120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 34/120 [1:00:54<2:29:48, 104.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 33\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 34 -step: 1 -running loss: 2.397\n",
            "Epoch: 34 -step: 2 -running loss: 2.396\n",
            "Epoch: 34 -step: 3 -running loss: 2.395\n",
            "Epoch: 34 -step: 4 -running loss: 2.394\n",
            "Epoch: 34 -step: 5 -running loss: 2.393\n",
            "Epoch: 34 -step: 6 -running loss: 2.391\n",
            "Epoch: 34 -step: 7 -running loss: 2.390\n",
            "Epoch: 34 -step: 8 -running loss: 2.389\n",
            "Epoch: 34 -step: 9 -running loss: 2.388\n",
            "Epoch: 34 -step: 10 -running loss: 2.387\n",
            "Epoch: 34 -step: 11 -running loss: 2.386\n",
            "Epoch: 34 -step: 12 -running loss: 2.385\n",
            "Epoch: 34 -step: 13 -running loss: 2.383\n",
            "Epoch: 34 -step: 14 -running loss: 2.382\n",
            "Epoch: 34 -step: 15 -running loss: 2.381\n",
            "Epoch: 34 -step: 16 -running loss: 2.380\n",
            "Epoch: 34 -step: 17 -running loss: 2.379\n",
            "Epoch: 34 -step: 18 -running loss: 2.378\n",
            "Epoch: 34 -step: 19 -running loss: 2.377\n",
            "Epoch: 34 -step: 20 -running loss: 2.376\n",
            "Epoch: 34 -step: 21 -running loss: 2.375\n",
            "Epoch: 34 -step: 22 -running loss: 2.373\n",
            "Epoch: 34 -step: 23 -running loss: 2.372\n",
            "Epoch: 34 -step: 24 -running loss: 2.371\n",
            "Epoch: 34 -step: 25 -running loss: 2.370\n",
            "Epoch: 34 -step: 26 -running loss: 2.369\n",
            "Epoch: 34 -step: 27 -running loss: 2.368\n",
            "Epoch: 34 -step: 28 -running loss: 2.367\n",
            "Epoch: 34 -step: 29 -running loss: 2.366\n",
            "Epoch: 34 -step: 30 -running loss: 2.365\n",
            "Epoch: 34 -step: 31 -running loss: 2.364\n",
            "Epoch: 34 -step: 32 -running loss: 2.362\n",
            "Epoch: 34 -step: 33 -running loss: 2.361\n",
            "Epoch: 34 -step: 34 -running loss: 2.360\n",
            "Epoch: 34 -step: 35 -running loss: 2.359\n",
            "Epoch: 34 -step: 36 -running loss: 2.358\n",
            "Epoch: 34 -step: 37 -running loss: 2.357\n",
            "Epoch: 34 -step: 38 -running loss: 2.356\n",
            "Epoch: 34 -step: 39 -running loss: 2.355\n",
            "Epoch: 34 -step: 40 -running loss: 2.354\n",
            "Epoch: 34 -step: 41 -running loss: 2.353\n",
            "Epoch: 34 -step: 42 -running loss: 2.352\n",
            "\n",
            "Epoch 35/120 - Training Loss: 2.374 - Validation Loss: 0.121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 35/120 [1:02:39<2:28:09, 104.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 34\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 35 -step: 1 -running loss: 2.350\n",
            "Epoch: 35 -step: 2 -running loss: 2.349\n",
            "Epoch: 35 -step: 3 -running loss: 2.348\n",
            "Epoch: 35 -step: 4 -running loss: 2.347\n",
            "Epoch: 35 -step: 5 -running loss: 2.346\n",
            "Epoch: 35 -step: 6 -running loss: 2.345\n",
            "Epoch: 35 -step: 7 -running loss: 2.344\n",
            "Epoch: 35 -step: 8 -running loss: 2.343\n",
            "Epoch: 35 -step: 9 -running loss: 2.342\n",
            "Epoch: 35 -step: 10 -running loss: 2.341\n",
            "Epoch: 35 -step: 11 -running loss: 2.340\n",
            "Epoch: 35 -step: 12 -running loss: 2.339\n",
            "Epoch: 35 -step: 13 -running loss: 2.338\n",
            "Epoch: 35 -step: 14 -running loss: 2.336\n",
            "Epoch: 35 -step: 15 -running loss: 2.335\n",
            "Epoch: 35 -step: 16 -running loss: 2.334\n",
            "Epoch: 35 -step: 17 -running loss: 2.333\n",
            "Epoch: 35 -step: 18 -running loss: 2.332\n",
            "Epoch: 35 -step: 19 -running loss: 2.331\n",
            "Epoch: 35 -step: 20 -running loss: 2.330\n",
            "Epoch: 35 -step: 21 -running loss: 2.329\n",
            "Epoch: 35 -step: 22 -running loss: 2.328\n",
            "Epoch: 35 -step: 23 -running loss: 2.327\n",
            "Epoch: 35 -step: 24 -running loss: 2.326\n",
            "Epoch: 35 -step: 25 -running loss: 2.325\n",
            "Epoch: 35 -step: 26 -running loss: 2.324\n",
            "Epoch: 35 -step: 27 -running loss: 2.323\n",
            "Epoch: 35 -step: 28 -running loss: 2.322\n",
            "Epoch: 35 -step: 29 -running loss: 2.321\n",
            "Epoch: 35 -step: 30 -running loss: 2.320\n",
            "Epoch: 35 -step: 31 -running loss: 2.319\n",
            "Epoch: 35 -step: 32 -running loss: 2.318\n",
            "Epoch: 35 -step: 33 -running loss: 2.316\n",
            "Epoch: 35 -step: 34 -running loss: 2.315\n",
            "Epoch: 35 -step: 35 -running loss: 2.314\n",
            "Epoch: 35 -step: 36 -running loss: 2.313\n",
            "Epoch: 35 -step: 37 -running loss: 2.312\n",
            "Epoch: 35 -step: 38 -running loss: 2.311\n",
            "Epoch: 35 -step: 39 -running loss: 2.310\n",
            "Epoch: 35 -step: 40 -running loss: 2.309\n",
            "Epoch: 35 -step: 41 -running loss: 2.308\n",
            "Epoch: 35 -step: 42 -running loss: 2.307\n",
            "\n",
            "Epoch 36/120 - Training Loss: 2.329 - Validation Loss: 0.121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 36/120 [1:04:24<2:26:21, 104.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 35\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 36 -step: 1 -running loss: 2.306\n",
            "Epoch: 36 -step: 2 -running loss: 2.305\n",
            "Epoch: 36 -step: 3 -running loss: 2.304\n",
            "Epoch: 36 -step: 4 -running loss: 2.303\n",
            "Epoch: 36 -step: 5 -running loss: 2.302\n",
            "Epoch: 36 -step: 6 -running loss: 2.301\n",
            "Epoch: 36 -step: 7 -running loss: 2.300\n",
            "Epoch: 36 -step: 8 -running loss: 2.299\n",
            "Epoch: 36 -step: 9 -running loss: 2.298\n",
            "Epoch: 36 -step: 10 -running loss: 2.297\n",
            "Epoch: 36 -step: 11 -running loss: 2.296\n",
            "Epoch: 36 -step: 12 -running loss: 2.295\n",
            "Epoch: 36 -step: 13 -running loss: 2.294\n",
            "Epoch: 36 -step: 14 -running loss: 2.293\n",
            "Epoch: 36 -step: 15 -running loss: 2.292\n",
            "Epoch: 36 -step: 16 -running loss: 2.291\n",
            "Epoch: 36 -step: 17 -running loss: 2.290\n",
            "Epoch: 36 -step: 18 -running loss: 2.289\n",
            "Epoch: 36 -step: 19 -running loss: 2.288\n",
            "Epoch: 36 -step: 20 -running loss: 2.287\n",
            "Epoch: 36 -step: 21 -running loss: 2.286\n",
            "Epoch: 36 -step: 22 -running loss: 2.285\n",
            "Epoch: 36 -step: 23 -running loss: 2.284\n",
            "Epoch: 36 -step: 24 -running loss: 2.283\n",
            "Epoch: 36 -step: 25 -running loss: 2.282\n",
            "Epoch: 36 -step: 26 -running loss: 2.281\n",
            "Epoch: 36 -step: 27 -running loss: 2.280\n",
            "Epoch: 36 -step: 28 -running loss: 2.279\n",
            "Epoch: 36 -step: 29 -running loss: 2.278\n",
            "Epoch: 36 -step: 30 -running loss: 2.277\n",
            "Epoch: 36 -step: 31 -running loss: 2.276\n",
            "Epoch: 36 -step: 32 -running loss: 2.275\n",
            "Epoch: 36 -step: 33 -running loss: 2.274\n",
            "Epoch: 36 -step: 34 -running loss: 2.273\n",
            "Epoch: 36 -step: 35 -running loss: 2.272\n",
            "Epoch: 36 -step: 36 -running loss: 2.271\n",
            "Epoch: 36 -step: 37 -running loss: 2.270\n",
            "Epoch: 36 -step: 38 -running loss: 2.269\n",
            "Epoch: 36 -step: 39 -running loss: 2.268\n",
            "Epoch: 36 -step: 40 -running loss: 2.267\n",
            "Epoch: 36 -step: 41 -running loss: 2.266\n",
            "Epoch: 36 -step: 42 -running loss: 2.265\n",
            "\n",
            "Epoch 37/120 - Training Loss: 2.285 - Validation Loss: 0.122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 37/120 [1:06:08<2:24:30, 104.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 36\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 37 -step: 1 -running loss: 2.264\n",
            "Epoch: 37 -step: 2 -running loss: 2.263\n",
            "Epoch: 37 -step: 3 -running loss: 2.262\n",
            "Epoch: 37 -step: 4 -running loss: 2.261\n",
            "Epoch: 37 -step: 5 -running loss: 2.260\n",
            "Epoch: 37 -step: 6 -running loss: 2.259\n",
            "Epoch: 37 -step: 7 -running loss: 2.258\n",
            "Epoch: 37 -step: 8 -running loss: 2.257\n",
            "Epoch: 37 -step: 9 -running loss: 2.256\n",
            "Epoch: 37 -step: 10 -running loss: 2.255\n",
            "Epoch: 37 -step: 11 -running loss: 2.254\n",
            "Epoch: 37 -step: 12 -running loss: 2.253\n",
            "Epoch: 37 -step: 13 -running loss: 2.252\n",
            "Epoch: 37 -step: 14 -running loss: 2.251\n",
            "Epoch: 37 -step: 15 -running loss: 2.250\n",
            "Epoch: 37 -step: 16 -running loss: 2.249\n",
            "Epoch: 37 -step: 17 -running loss: 2.248\n",
            "Epoch: 37 -step: 18 -running loss: 2.247\n",
            "Epoch: 37 -step: 19 -running loss: 2.246\n",
            "Epoch: 37 -step: 20 -running loss: 2.245\n",
            "Epoch: 37 -step: 21 -running loss: 2.245\n",
            "Epoch: 37 -step: 22 -running loss: 2.244\n",
            "Epoch: 37 -step: 23 -running loss: 2.243\n",
            "Epoch: 37 -step: 24 -running loss: 2.242\n",
            "Epoch: 37 -step: 25 -running loss: 2.241\n",
            "Epoch: 37 -step: 26 -running loss: 2.240\n",
            "Epoch: 37 -step: 27 -running loss: 2.239\n",
            "Epoch: 37 -step: 28 -running loss: 2.238\n",
            "Epoch: 37 -step: 29 -running loss: 2.237\n",
            "Epoch: 37 -step: 30 -running loss: 2.236\n",
            "Epoch: 37 -step: 31 -running loss: 2.235\n",
            "Epoch: 37 -step: 32 -running loss: 2.234\n",
            "Epoch: 37 -step: 33 -running loss: 2.233\n",
            "Epoch: 37 -step: 34 -running loss: 2.232\n",
            "Epoch: 37 -step: 35 -running loss: 2.231\n",
            "Epoch: 37 -step: 36 -running loss: 2.230\n",
            "Epoch: 37 -step: 37 -running loss: 2.229\n",
            "Epoch: 37 -step: 38 -running loss: 2.228\n",
            "Epoch: 37 -step: 39 -running loss: 2.228\n",
            "Epoch: 37 -step: 40 -running loss: 2.227\n",
            "Epoch: 37 -step: 41 -running loss: 2.226\n",
            "Epoch: 37 -step: 42 -running loss: 2.225\n",
            "\n",
            "Epoch 38/120 - Training Loss: 2.244 - Validation Loss: 0.123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 38/120 [1:07:52<2:22:34, 104.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 37\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "Epoch: 38 -step: 1 -running loss: 2.224\n",
            "Epoch: 38 -step: 2 -running loss: 2.223\n",
            "Epoch: 38 -step: 3 -running loss: 2.222\n",
            "Epoch: 38 -step: 4 -running loss: 2.221\n",
            "Epoch: 38 -step: 5 -running loss: 2.220\n",
            "Epoch: 38 -step: 6 -running loss: 2.219\n",
            "Epoch: 38 -step: 7 -running loss: 2.218\n",
            "Epoch: 38 -step: 8 -running loss: 2.217\n",
            "Epoch: 38 -step: 9 -running loss: 2.216\n",
            "Epoch: 38 -step: 10 -running loss: 2.215\n",
            "Epoch: 38 -step: 11 -running loss: 2.215\n",
            "Epoch: 38 -step: 12 -running loss: 2.214\n",
            "Epoch: 38 -step: 13 -running loss: 2.213\n",
            "Epoch: 38 -step: 14 -running loss: 2.212\n",
            "Epoch: 38 -step: 15 -running loss: 2.211\n",
            "Epoch: 38 -step: 16 -running loss: 2.210\n",
            "Epoch: 38 -step: 17 -running loss: 2.209\n",
            "Epoch: 38 -step: 18 -running loss: 2.208\n",
            "Epoch: 38 -step: 19 -running loss: 2.207\n",
            "Epoch: 38 -step: 20 -running loss: 2.206\n",
            "Epoch: 38 -step: 21 -running loss: 2.205\n",
            "Epoch: 38 -step: 22 -running loss: 2.204\n"
          ]
        }
      ],
      "source": [
        "epochs = 120\n",
        "batch_size = 24\n",
        "n_examples_per_class = 6\n",
        "EMA_lr = 0.9\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#     monitor='val_loss',\n",
        "#     factor=0.5,\n",
        "#     patience=10,\n",
        "#     min_lr=1e-6,\n",
        "#     verbose=1\n",
        "# )\n",
        "num_steps_per_epoch = len(x_train) // batch_size\n",
        "\n",
        "# Calculate initial centers\n",
        "centers = tf.Variable(initial_value=tf.random.normal((102, 1024), mean=0.0, stddev=0.5))\n",
        "\n",
        "# Loop through all samples\n",
        "for index in range(102):\n",
        "    # category_features = all_features[y_train == index]\n",
        "    category_center = all_features[y_train == index]\n",
        "    # if len(category_features) > 0:\n",
        "    if len(category_center) > 0 :\n",
        "        # category_center = tf.reduce_mean(category_features, axis=0)\n",
        "        centers[index].assign(category_center)\n",
        "\n",
        "# Training\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "\n",
        "    # Schedule the alpha\n",
        "    if epoch < (epochs)/3:\n",
        "        alpha = 0.1\n",
        "    elif (epochs)/3 < epoch < (epochs)*2/3 :\n",
        "        alpha = 0.25\n",
        "    else:\n",
        "        alpha = 0.5\n",
        "\n",
        "    # Create batch generator for the current epoch\n",
        "    batch_generator = batch_me(images=x_train, labels=y_train, batch_size=batch_size, samples_per_class=n_examples_per_class)\n",
        "\n",
        "    for batch_idx in range(num_steps_per_epoch):\n",
        "        if batch_idx == 0:\n",
        "            print(\"\\n\")\n",
        "        # Get the next batch\n",
        "        batch_x, batch_y = next(batch_generator)\n",
        "        # Capture Gradients\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            # Extract Features per batch\n",
        "            predictions = model(batch_x)\n",
        "            # train_preds.extend(predictions.numpy())\n",
        "            train_preds.extend(predictions)\n",
        "            train_labels.extend(tf.one_hot(batch_y, 102))\n",
        "\n",
        "            # initialize batch centers\n",
        "            batch_centers = centers.numpy()[batch_y]\n",
        "\n",
        "            # Calculate Batch Centers\n",
        "            for index in range(batch_size):\n",
        "                instance_feature = feature_extraction_model(np.expand_dims(batch_x[index], axis=0))\n",
        "                instance_mean = tf.reduce_mean(instance_feature[0], axis=0)\n",
        "                batch_centers[index] = [instance_mean] * 1024\n",
        "\n",
        "            # Center-Loss calculation\n",
        "            c_loss = center_loss(instance_feature, batch_centers)\n",
        "            # Combine it with CategoricalCrossEntropyLoss\n",
        "            cls_loss = tf.keras.losses.CategoricalCrossentropy()(tf.one_hot(batch_y, 102), predictions)\n",
        "            # Total Loss\n",
        "            loss = (c_loss * alpha) + cls_loss\n",
        "\n",
        "        # Calculate Gradients\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # Update training loss\n",
        "        total_loss += loss\n",
        "        num_batches += 1\n",
        "        print(f\"Epoch: {epoch} -step: {num_batches} -running loss: {loss:.3f}\")\n",
        "\n",
        "\n",
        "    # Calculate training Loss\n",
        "    training_loss = total_loss / num_batches\n",
        "\n",
        "    ### DEBUGGIN\n",
        "    # print(f\"train_preds: {train_preds}\")\n",
        "    # print(f\"train_preds shape: {train_preds}\")\n",
        "    # print(\"=\"*100)\n",
        "    # print(f\"train_preds: {train_labels}\")\n",
        "    # print(f\"train_preds shape: {train_labels.shape}\")\n",
        "    ### END OF DEBUGGIN\n",
        "\n",
        "    \"\"\"Calculate AUC and ROC for training\"\"\"\n",
        "    # train_auc = roc_auc_score(tf.one_hot(np.argmax(train_labels, axis=1), 102), train_preds, multi_class='ovr')\n",
        "    # train_auc = tf.keras.metrics.AUC()(tf.one_hot(np.argmax(train_labels, axis=1), 102), train_preds).numpy()\n",
        "    # train_fpr, train_tpr, _ = roc_curve(tf.one_hot(np.argmax(train_labels, axis=1), 102), train_preds, pos_label=None)\n",
        "    # train_accuracy = tf.keras.metrics.Accuracy()(np.argmax(train_labels, axis=1), np.argmax(train_preds, axis=1)).numpy()\n",
        "\n",
        "\n",
        "    \"\"\"Validation Loop\"\"\"\n",
        "    val_batch_generator = batch_me(images=x_test, labels=y_test, batch_size=batch_size, samples_per_class=n_examples_per_class)\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    for step in range(num_steps_per_epoch):\n",
        "        val_batch_x, val_batch_y = next(val_batch_generator)\n",
        "        # Make Predictions\n",
        "        val_predictions = model(val_batch_x, training=False)\n",
        "        # val_preds.extend(val_predictions.numpy())\n",
        "        val_preds.extend(val_predictions)\n",
        "        val_labels.extend(val_batch_y)\n",
        "        # Init Centers\n",
        "        val_batch_centers = centers.numpy()[val_batch_y]\n",
        "\n",
        "\n",
        "    # Center Calcualtion\n",
        "    for idx in range(batch_size):\n",
        "        val_instance_features = feature_extraction_model(np.expand_dims(val_batch_x[idx], axis=0))\n",
        "        val_instance_mean = tf.reduce_mean(val_instance_features[0], axis=0)\n",
        "        val_batch_centers[idx] = val_instance_mean * 1024\n",
        "\n",
        "\n",
        "    # Loss Calculation\n",
        "    val_c_loss = center_loss(val_instance_features, val_batch_centers)\n",
        "    val_cls_loss = tf.keras.losses.CategoricalCrossentropy()(tf.one_hot(val_batch_y, 102), val_predictions)\n",
        "    val_loss = (val_c_loss * alpha) + val_cls_loss\n",
        "    val_loss = val_loss / num_batches\n",
        "\n",
        "    # lr_scheduler.on_epoch_end(epoch, logs={'val_loss': val_loss.numpy()})\n",
        "\n",
        "    \"\"\"AUC ROC ACC Calculation\"\"\"\n",
        "    val_auc = tf.keras.metrics.AUC()(tf.one_hot(val_labels, 102), val_preds).numpy()\n",
        "    # val_fpr, val_tpr, _ = roc_curve(tf.one_hot(np.argmax(val_labels, axis=1), 102), val_preds, pos_label=None)\n",
        "    # val_accuracy = tf.keras.metrics.Accuracy()(np.argmax(val_labels, axis=1), np.argmax(val_preds, axis=1)).numpy()\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs} - Training Loss: {training_loss:.3f} - Validation Loss: {val_loss.numpy():.3f}\")\n",
        "    val_losses.append(val_loss)\n",
        "    train_losses.append(training_loss)\n",
        "    # print(f\"Training AUC: {train_auc:.3f} - Validation AUC: {val_auc:.3f}\")\n",
        "    # print(f\"Training Accuracy: {train_accuracy:.3f} - Validation Accuracy: {val_accuracy:.3f}\")\n",
        "\n",
        "\n",
        "    # Centers Update Frequency\n",
        "    for index in range(102):\n",
        "        category_features = all_features[y_train == index]\n",
        "        if len(category_features)>0:\n",
        "            category_center = tf.reduce_mean(category_features, axis=0)\n",
        "            # centers[index].assign((1.0 - EMA_lr) * centers[index]) + (EMA_lr * category_center)\n",
        "            centers[index].assign((1.0 - EMA_lr) * tf.cast(centers[index], tf.float32) + (EMA_lr * tf.cast(category_center, tf.float32)))\n",
        "    print(f\"Centers updated - Step : {epoch}\")\n",
        "    print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAXZXS4RDoA-"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.lineplot(x=np.arange(1,121), y = [index.numpy() for index in val_losses])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVVIOI32HFtd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWEI1mz0Dxy6"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/model_v0_120.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t1hCEdmF3cA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}