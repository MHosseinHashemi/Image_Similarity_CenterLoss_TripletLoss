{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiZUcTwyz/IcA2+2EBHLY/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHosseinHashemi/Image_Similarity/blob/main/Image_Simmilarity_CenterLoss_TF_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LESsrUWdiKeV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, RandomFlip, RandomRotation, Dense, Dropout, Lambda\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, test_data, validation_data), info = tfds.load(\"oxford_flowers102\", split=['train', 'validation', 'test'], as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "TsP2sQmQiTo2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height = 128\n",
        "width = 128\n",
        "\n",
        "def preprocess_images(image, label, height, width):\n",
        "    # image = tf.image.resize_with_crop_or_pad(image, target_height=height, target_width=width)\n",
        "    image = tf.image.resize(image, [width, height])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n"
      ],
      "metadata": {
        "id": "hs5-5Z9YiUSB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_data.map(lambda image, label: preprocess_images(image, label, height, width))"
      ],
      "metadata": {
        "id": "XkPAI7_qiUUS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = test_data.map(lambda image, label: preprocess_images(image, label, height, width))"
      ],
      "metadata": {
        "id": "J_pYE9-EiUW6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loader(data):\n",
        "  x = []\n",
        "  y = []\n",
        "  for img, label in tqdm(data.as_numpy_iterator()):\n",
        "    x.append(img)\n",
        "    y.append(label)\n",
        "\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "KktpIh3LiUZb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = data_loader(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpAEgn23iUbS",
        "outputId": "cdc2fb9f-ba74-4d1f-b4f4-acb8877798a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1020it [00:01, 561.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = data_loader(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGHyCXxoihTz",
        "outputId": "aa96df5d-2ba9-45ab-de3f-e5956213e027"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1020it [00:01, 560.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Model\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2\"\n",
        "\n",
        "input_layer = Input(shape=(height, width, 3))\n",
        "x = RandomFlip()(input_layer)\n",
        "x = RandomRotation(0.3)(x)\n",
        "x = hub.KerasLayer(MODEL_URL, trainable=True)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(128, activation=None)(x)\n",
        "x = Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)  # L2 normalize embeddings\n",
        "output_layer = Dense(102, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DmQk9fAihWB",
        "outputId": "fabf3e2f-65ad-495f-9793-186897c5da0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " random_flip (RandomFlip)    (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " random_rotation (RandomRota  (None, 128, 128, 3)      0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " keras_layer (KerasLayer)    (None, 1280)              20331360  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               163968    \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 102)               13158     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,508,486\n",
            "Trainable params: 20,354,614\n",
            "Non-trainable params: 153,872\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_me(images, labels, batch_size, samples_per_class):\n",
        "  temp_dict = defaultdict(list) # A Dic of Lists to save img, label pairs as one object\n",
        "  for img, label in zip(images, labels):\n",
        "    temp_dict[label].append(img)\n",
        "\n",
        "  while True:\n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    while len(batch_x) < batch_size:\n",
        "      for category, examples in temp_dict.items():\n",
        "        # Only feed as large as the \"samples per class\"\n",
        "        # If the batch did not had enough space, feed as much as it has\n",
        "        n_samples = min(samples_per_class, (batch_size - len(batch_x)))\n",
        "        if n_samples == 0:\n",
        "          break\n",
        "        # Pick randomly from simmilar images of the same category\n",
        "        samples = random.sample(examples, k=n_samples)\n",
        "        # Add corresponding x, y values to the batch\n",
        "        batch_x.extend(samples)\n",
        "        batch_y.extend([category] * len(samples))\n",
        "\n",
        "\n",
        "    # It should be a continous operation\n",
        "    yield np.array(batch_x), np.array(batch_y)\n"
      ],
      "metadata": {
        "id": "wUEsVIwEihYl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def center_loss(feature_vector, center):\n",
        "    difference = feature_vector - center\n",
        "    loss = tf.reduce_mean(tf.reduce_sum(difference**2, axis=1))\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "wOQRKkqNwmG5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "nK7pcdXVohII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extraction_model = Model(inputs=model.input, outputs=model.layers[-2].output)"
      ],
      "metadata": {
        "id": "id5Jbcj7Ong9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_features = {}\n",
        "class_feature_vectors = {}  # Store pre-calculated feature vectors for each class\n",
        "\n",
        "# Calculate and store class feature vectors\n",
        "for x, y in zip(x_train, y_train):\n",
        "    if y not in class_feature_vectors:\n",
        "        feature_vector = feature_extraction_model.predict(np.expand_dims(x, axis=0)).mean()\n",
        "        class_feature_vectors[y] = feature_vector\n",
        "\n",
        "# Calculate raw_features using class_feature_vectors\n",
        "for x, y in zip(x_train, y_train):\n",
        "    if y in raw_features:\n",
        "        new_center = feature_extraction_model.predict(np.expand_dims(x, axis=0)).mean()\n",
        "        raw_features[y] = [(prev + new_center) / 2 for prev in raw_features[y]]\n",
        "    else:\n",
        "        raw_features[y] = [class_feature_vectors[y]] * 128\n",
        "\n",
        "all_features = {key: value for key, value in raw_features.items()}\n",
        "\n",
        "# Clean up memory\n",
        "del class_feature_vectors\n"
      ],
      "metadata": {
        "id": "HE02PKJdOL0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "Yy94s6HnkWx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "alpha = 0.5\n",
        "batch_size = 32\n",
        "n_examples_per_class = 4\n",
        "EMA_lr = 0.9\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
        "num_steps_per_epoch = len(x_train) // batch_size\n",
        "\n",
        "# Calculate initial centers\n",
        "centers = tf.Variable(initial_value=tf.random.normal((102, 128), mean=0.0, stddev=0.5))\n",
        "\n",
        "# Loop through all samples\n",
        "for index in range(102):\n",
        "    # category_features = all_features[y_train == index]\n",
        "    category_center = all_features[y_train == index]\n",
        "    # if len(category_features) > 0:\n",
        "    if len(category_center) > 0 :\n",
        "        # category_center = tf.reduce_mean(category_features, axis=0)\n",
        "        centers[index].assign(category_center)\n",
        "\n",
        "# Training\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    train_preds = []\n",
        "    train_labels = []\n",
        "\n",
        "    # Create batch generator for the current epoch\n",
        "    batch_generator = batch_me(images=x_train, labels=y_train, batch_size=batch_size, samples_per_class=n_examples_per_class)\n",
        "\n",
        "    for batch_idx in range(num_steps_per_epoch):\n",
        "        if batch_idx == 0:\n",
        "            print(\"\\n\")\n",
        "        # Get the next batch\n",
        "        batch_x, batch_y = next(batch_generator)\n",
        "        # Capture Gradients\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            # Extract Features per batch\n",
        "            predictions = model(batch_x, training=False)\n",
        "            # train_preds.extend(predictions.numpy())\n",
        "            train_preds.extend(predictions)\n",
        "            train_labels.extend(tf.one_hot(batch_y, 102))\n",
        "\n",
        "            # initialize batch centers\n",
        "            batch_centers = centers.numpy()[batch_y]\n",
        "\n",
        "            # Calculate Batch Centers\n",
        "            for index in range(batch_size):\n",
        "                instance_feature = feature_extraction_model(np.expand_dims(batch_x[index], axis=0))\n",
        "                instance_mean = tf.reduce_mean(instance_feature[0], axis=0)\n",
        "                batch_centers[index] = [instance_mean] * 128\n",
        "\n",
        "            # Center-Loss calculation\n",
        "            c_loss = center_loss(instance_feature, batch_centers)\n",
        "            # Combine it with CategoricalCrossEntropyLoss\n",
        "            cls_loss = tf.keras.losses.CategoricalCrossentropy()(tf.one_hot(batch_y, 102), predictions)\n",
        "            # Total Loss\n",
        "            loss = (c_loss * alpha) + cls_loss\n",
        "\n",
        "        # Calculate Gradients\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # Update training loss\n",
        "        total_loss += loss\n",
        "        num_batches += 1\n",
        "        print(f\"Epoch: {epoch} -step: {num_batches} -running loss: {loss:.3f}\")\n",
        "\n",
        "\n",
        "    # Calculate training Loss\n",
        "    training_loss = total_loss / num_batches\n",
        "\n",
        "    ### DEBUGGIN\n",
        "    # print(f\"train_preds: {train_preds}\")\n",
        "    # print(f\"train_preds shape: {train_preds}\")\n",
        "    # print(\"=\"*100)\n",
        "    # print(f\"train_preds: {train_labels}\")\n",
        "    # print(f\"train_preds shape: {train_labels.shape}\")\n",
        "    ### END OF DEBUGGIN\n",
        "\n",
        "    \"\"\"Calculate AUC and ROC for training\"\"\"\n",
        "    # train_auc = roc_auc_score(tf.one_hot(np.argmax(train_labels, axis=1), 102), train_preds, multi_class='ovr')\n",
        "    # train_auc = tf.keras.metrics.AUC()(tf.one_hot(np.argmax(train_labels, axis=1), 102), train_preds).numpy()\n",
        "    # train_fpr, train_tpr, _ = roc_curve(tf.one_hot(np.argmax(train_labels, axis=1), 102), train_preds, pos_label=None)\n",
        "    # train_accuracy = tf.keras.metrics.Accuracy()(np.argmax(train_labels, axis=1), np.argmax(train_preds, axis=1)).numpy()\n",
        "\n",
        "\n",
        "    \"\"\"Validation Loop\"\"\"\n",
        "    val_batch_generator = batch_me(images=x_test, labels=y_test, batch_size=batch_size, samples_per_class=n_examples_per_class)\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    for step in range(num_steps_per_epoch):\n",
        "        val_batch_x, val_batch_y = next(val_batch_generator)\n",
        "        # Make Predictions\n",
        "        val_predictions = model(val_batch_x, training=False)\n",
        "        # val_preds.extend(val_predictions.numpy())\n",
        "        val_preds.extend(val_predictions)\n",
        "        val_labels.extend(val_batch_y)\n",
        "        # Init Centers\n",
        "        val_batch_centers = centers.numpy()[val_batch_y]\n",
        "\n",
        "\n",
        "    # Center Calcualtion\n",
        "    for idx in range(batch_size):\n",
        "        val_instance_features = feature_extraction_model(np.expand_dims(val_batch_x[idx], axis=0))\n",
        "        val_instance_mean = tf.reduce_mean(val_instance_features[0], axis=0)\n",
        "        val_batch_centers[idx] = val_instance_mean * 128\n",
        "\n",
        "\n",
        "    # Loss Calculation\n",
        "    val_c_loss = center_loss(val_instance_features, val_batch_centers)\n",
        "    val_cls_loss = tf.keras.losses.CategoricalCrossentropy()(tf.one_hot(val_batch_y, 102), val_predictions)\n",
        "    val_loss = (val_c_loss * alpha) + val_cls_loss\n",
        "    val_loss = val_loss / num_batches\n",
        "\n",
        "\n",
        "    \"\"\"AUC ROC ACC Calculation\"\"\"\n",
        "    val_auc = tf.keras.metrics.AUC()(tf.one_hot(val_labels, 102), val_preds).numpy()\n",
        "    # val_fpr, val_tpr, _ = roc_curve(tf.one_hot(np.argmax(val_labels, axis=1), 102), val_preds, pos_label=None)\n",
        "    # val_accuracy = tf.keras.metrics.Accuracy()(np.argmax(val_labels, axis=1), np.argmax(val_preds, axis=1)).numpy()\n",
        "\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs} - Training Loss: {training_loss:.3f} - Validation Loss: {val_loss.numpy():.3f}\")\n",
        "    # print(f\"Training AUC: {train_auc:.3f} - Validation AUC: {val_auc:.3f}\")\n",
        "    # print(f\"Training Accuracy: {train_accuracy:.3f} - Validation Accuracy: {val_accuracy:.3f}\")\n",
        "\n",
        "\n",
        "    # Centers Update Frequency\n",
        "    for index in range(102):\n",
        "        category_features = all_features[y_train == index]\n",
        "        if len(category_features)>0:\n",
        "            category_center = tf.reduce_mean(category_features, axis=0)\n",
        "            # centers[index].assign((1.0 - EMA_lr) * centers[index]) + (EMA_lr * category_center)\n",
        "            centers[index].assign((1.0 - EMA_lr) * tf.cast(centers[index], tf.float32) + (EMA_lr * tf.cast(category_center, tf.float32)))\n",
        "    print(f\"Centers updated - Step : {epoch}\")\n",
        "    print(\"=\"*100)\n"
      ],
      "metadata": {
        "id": "0UAmPnDANvNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-vRJklI8ujjW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}