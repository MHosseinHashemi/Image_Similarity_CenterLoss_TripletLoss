{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOV5s8b91Z6cBNwOnVThlov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHosseinHashemi/Image_Similarity/blob/main/Image_Simmilarity_CenterLoss_TF_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LESsrUWdiKeV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, RandomFlip, RandomRotation, Dense, Dropout, Lambda\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_data, test_data, validation_data), info = tfds.load(\"oxford_flowers102\", split=['train', 'validation', 'test'], as_supervised=True, with_info=True)"
      ],
      "metadata": {
        "id": "TsP2sQmQiTo2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height = 128\n",
        "width = 128\n",
        "\n",
        "def preprocess_images(image, label, height, width):\n",
        "    # image = tf.image.resize_with_crop_or_pad(image, target_height=height, target_width=width)\n",
        "    image = tf.image.resize(image, [width, height])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n"
      ],
      "metadata": {
        "id": "hs5-5Z9YiUSB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_data.map(lambda image, label: preprocess_images(image, label, height, width))"
      ],
      "metadata": {
        "id": "XkPAI7_qiUUS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = test_data.map(lambda image, label: preprocess_images(image, label, height, width))"
      ],
      "metadata": {
        "id": "J_pYE9-EiUW6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loader(data):\n",
        "  x = []\n",
        "  y = []\n",
        "  for img, label in tqdm(data.as_numpy_iterator()):\n",
        "    x.append(img)\n",
        "    y.append(label)\n",
        "\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "KktpIh3LiUZb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = data_loader(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpAEgn23iUbS",
        "outputId": "c4a69c78-348b-4511-beda-b7fb9046bfac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1020it [00:01, 542.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test, y_test = data_loader(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGHyCXxoihTz",
        "outputId": "e447fc0a-0cee-42e1-ac2c-26c1ce8734a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1020it [00:02, 438.10it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Model\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2\"\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.RandomFlip(),\n",
        "#     tf.keras.layers.RandomRotation(0.3),\n",
        "#     hub.KerasLayer(MODEL_URL, trainable=True),\n",
        "#     tf.keras.layers.Dropout(0.25),\n",
        "#     tf.keras.layers.Dense(128, activation=None),\n",
        "#     tf.keras.layers.Dense(102, activation='softmax')\n",
        "#     # tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
        "# ])\n",
        "\n",
        "# model.build([None, height, height, 3])\n",
        "# model.summary()\n",
        "\n",
        "# With Functional API to prevent Further Err\n",
        "input_layer = Input(shape=(height, width, 3))\n",
        "x = RandomFlip()(input_layer)\n",
        "x = RandomRotation(0.3)(x)\n",
        "x = hub.KerasLayer(MODEL_URL, trainable=True)(x)\n",
        "x = Dropout(0.25)(x)\n",
        "x = Dense(128, activation=None)(x)\n",
        "x = Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)  # L2 normalize embeddings\n",
        "output_layer = Dense(102, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DmQk9fAihWB",
        "outputId": "7b597490-8fb2-4d6c-830a-733a76428a7d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " random_flip (RandomFlip)    (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " random_rotation (RandomRota  (None, 128, 128, 3)      0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " keras_layer (KerasLayer)    (None, 1280)              20331360  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               163968    \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 102)               13158     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,508,486\n",
            "Trainable params: 20,354,614\n",
            "Non-trainable params: 153,872\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_me(images, labels, batch_size, samples_per_class):\n",
        "  temp_dict = defaultdict(list) # A Dic of Lists to save img, label pairs as one object\n",
        "  # batch_count = 0  # just for debugging ...\n",
        "  for img, label in zip(images, labels):\n",
        "    temp_dict[label].append(img)\n",
        "\n",
        "  while True:\n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    while len(batch_x) < batch_size:\n",
        "      for category, examples in temp_dict.items():\n",
        "        # Only feed as large as the \"samples per class\"\n",
        "        # If the batch did not had enough space, feed as much as it has\n",
        "        n_samples = min(samples_per_class, (batch_size - len(batch_x)))\n",
        "        if n_samples == 0:\n",
        "          break\n",
        "        # Pick randomly from simmilar images of the same category\n",
        "        samples = random.sample(examples, k=n_samples)\n",
        "        # Add corresponding x, y values to the batch\n",
        "        batch_x.extend(samples)\n",
        "        batch_y.extend([category] * len(samples))\n",
        "        # batch_count += 1  # Increment the counter\n",
        "\n",
        "\n",
        "    # print(f\"\\nBatch count: {batch_count}\") # just for debugging ...\n",
        "    # It should be a continous operation\n",
        "    yield np.array(batch_x), np.array(batch_y)\n"
      ],
      "metadata": {
        "id": "wUEsVIwEihYl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def center_loss(feature_vector, center):\n",
        "    difference = feature_vector - center\n",
        "    loss = tf.reduce_mean(tf.reduce_sum(difference**2, axis=1))\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "wOQRKkqNwmG5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "nK7pcdXVohII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extraction_model = Model(inputs=model.input, outputs=model.layers[-2].output)"
      ],
      "metadata": {
        "id": "id5Jbcj7Ong9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extarct All feature vectors and their corresponding centers\n",
        "# raw_features = {}\n",
        "# for k in tqdm(range(len(x_train))):\n",
        "#     if y_train[k] in raw_features.keys():\n",
        "#         # Avergae the new center with the previous one and replace it\n",
        "#         new_center = feature_extraction_model.predict(np.expand_dims(x_train[k], axis=0)).mean()\n",
        "#         prev_center = raw_features[y_train[k]]\n",
        "#         raw_features[y_train[k]] = [(prev_center + new_center )/2] * 128\n",
        "#         del new_center, prev_center\n",
        "\n",
        "#     else:\n",
        "#         raw_features[y_train[k]].append([feature_extraction_model.predict(np.expand_dims(x_train[k], axis=0)).mean()] * 128)\n",
        "\n",
        "\n",
        "# all_features = {key: value for key, value in raw_features.items()}\n",
        "\n",
        "# del raw_features,\n",
        "# all_features"
      ],
      "metadata": {
        "id": "2VuaST8e5ouV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raw_features = {}\n",
        "\n",
        "# for k, (x, y) in tqdm(enumerate(zip(x_train, y_train))):\n",
        "#     if y in raw_features:\n",
        "#         new_center = feature_extraction_model.predict(np.expand_dims(x, axis=0)).mean()\n",
        "#         prev_center = raw_features[y]\n",
        "#         averaged_center = [(prev + new_center) / 2 for prev in prev_center]\n",
        "#         raw_features[y] = [averaged_center] * 128\n",
        "#     else:\n",
        "#         feature_vector = feature_extraction_model.predict(np.expand_dims(x, axis=0)).mean()\n",
        "#         raw_features[y] = [feature_vector] * 128\n",
        "\n",
        "# all_features = {key: value for key, value in raw_features.items()}"
      ],
      "metadata": {
        "id": "CAinT3Y_MgRW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_features = {}\n",
        "class_feature_vectors = {}  # Store pre-calculated feature vectors for each class\n",
        "\n",
        "# Calculate and store class feature vectors\n",
        "for x, y in zip(x_train, y_train):\n",
        "    if y not in class_feature_vectors:\n",
        "        feature_vector = feature_extraction_model.predict(np.expand_dims(x, axis=0)).mean()\n",
        "        class_feature_vectors[y] = feature_vector\n",
        "\n",
        "# Calculate raw_features using class_feature_vectors\n",
        "for x, y in zip(x_train, y_train):\n",
        "    if y in raw_features:\n",
        "        new_center = feature_extraction_model.predict(np.expand_dims(x, axis=0)).mean()\n",
        "        raw_features[y] = [(prev + new_center) / 2 for prev in raw_features[y]]\n",
        "    else:\n",
        "        raw_features[y] = [class_feature_vectors[y]] * 128\n",
        "\n",
        "all_features = {key: value for key, value in raw_features.items()}\n",
        "\n",
        "# Clean up memory\n",
        "del class_feature_vectors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE02PKJdOL0A",
        "outputId": "343a782d-2a11-4d30-9398-1a1b3a2a9fce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "Yy94s6HnkWx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "alpha = 0.5\n",
        "batch_size = 32\n",
        "n_examples_per_class = 4\n",
        "EMA_lr = 0.9\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0003)\n",
        "num_steps_per_epoch = len(x_train) // batch_size\n",
        "\n",
        "# Calculate initial centers\n",
        "centers = tf.Variable(initial_value=tf.random.normal((102, 128), mean=0.0, stddev=0.5))\n",
        "\n",
        "# Loop through all samples\n",
        "for index in range(102):\n",
        "    # category_features = all_features[y_train == index]\n",
        "    category_center = all_features[y_train == index]\n",
        "    # if len(category_features) > 0:\n",
        "    if len(category_center) > 0 :\n",
        "        # category_center = tf.reduce_mean(category_features, axis=0)\n",
        "        centers[index].assign(category_center)\n",
        "\n",
        "# Training\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    # Create batch generator for the current epoch\n",
        "    batch_generator = batch_me(images=x_train, labels=y_train, batch_size=batch_size, samples_per_class=n_examples_per_class)\n",
        "\n",
        "    for batch_idx in range(num_steps_per_epoch):\n",
        "        # Get the next batch\n",
        "        batch_x, batch_y = next(batch_generator)\n",
        "        # Capture Gradients\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Extract Features per batch\n",
        "            predictions = model(batch_x, training=False)\n",
        "            # initialize batch centers\n",
        "            batch_centers = centers.numpy()[batch_y]\n",
        "\n",
        "            # Calculate Batch Centers\n",
        "            for index in range(batch_size):\n",
        "                instance_feature = feature_extraction_model(np.expand_dims(batch_x[index], axis=0))\n",
        "                instance_mean = tf.reduce_mean(instance_feature[0], axis=0)\n",
        "                batch_centers[index] = [instance_mean] * 128\n",
        "\n",
        "            # Center-Loss calculation\n",
        "            c_loss = center_loss(instance_feature, batch_centers)\n",
        "            # Combine it with CategoricalCrossEntropyLoss\n",
        "            cls_loss = tf.keras.losses.CategoricalCrossentropy()(tf.one_hot(batch_y, 102), predictions)\n",
        "            # Total Loss\n",
        "            loss = (c_loss * alpha) + cls_loss\n",
        "\n",
        "        # Calculate Gradients\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # Update training loss\n",
        "        total_loss += loss\n",
        "        num_batches += 1\n",
        "        print(f\"\\nEpoch: {epoch} - step: {num_batches} - running loss: {loss:.3f}\")\n",
        "\n",
        "    # Calculate training Loss\n",
        "    training_loss = total_loss / num_batches\n",
        "\n",
        "\n",
        "    \"\"\"Validation Loop\"\"\"\n",
        "    val_batch_generator = batch_me(images=x_test, labels=y_test, batch_size=batch_size, samples_per_class=n_examples_per_class)\n",
        "\n",
        "    for step in range(num_steps_per_epoch):\n",
        "        val_batch_x, val_batch_y = next(val_batch_generator)\n",
        "        # Make Predictions and Init Centers\n",
        "        val_predictions = model(val_batch_x, training=False)\n",
        "        val_batch_centers = centers.numpy()[val_batch_y]\n",
        "\n",
        "    # Center Calcualtion\n",
        "    for idx in range(batch_size):\n",
        "        val_instance_features = feature_extraction_model(np.expand_dims(val_batch_x[idx], axis=0))\n",
        "        val_instance_mean = tf.reduce_mean(val_instance_features[0], axis=0)\n",
        "        val_batch_centers[idx] = val_instance_mean * 128\n",
        "\n",
        "    # Loss Calculation\n",
        "    val_c_loss = center_loss(val_instance_features, val_batch_centers)\n",
        "    val_cls_loss = tf.keras.losses.CategoricalCrossentropy()(tf.one_hot(val_batch_y, 102), val_predictions)\n",
        "    val_loss = (val_c_loss * alpha) + val_cls_loss\n",
        "    val_loss = val_loss / num_batches\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Training Loss: {training_loss:.4f} - Validation Loss: {val_loss.numpy():.4f}\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    # Centers Update Frequency\n",
        "    for index in range(102):\n",
        "        category_features = all_features[y_train == index]\n",
        "        if len(category_features)>0:\n",
        "            category_center = tf.reduce_mean(category_features, axis=0)\n",
        "            # centers[index].assign((1.0 - EMA_lr) * centers[index]) + (EMA_lr * category_center)\n",
        "            centers[index].assign((1.0 - EMA_lr) * tf.cast(centers[index], tf.float32) + (EMA_lr * tf.cast(category_center, tf.float32)))\n",
        "    print(f\"Centers updated - Step : {epoch}\\n\")\n"
      ],
      "metadata": {
        "id": "bKK1T4Aqiha8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b09e55b-6875-41b3-aca9-93ab482e5f9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7eb6effde290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7eb6effde290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0 - step: 1 - running loss: 5.126\n",
            "\n",
            "Epoch: 0 - step: 2 - running loss: 4.820\n",
            "\n",
            "Epoch: 0 - step: 3 - running loss: 4.666\n",
            "\n",
            "Epoch: 0 - step: 4 - running loss: 4.534\n",
            "\n",
            "Epoch: 0 - step: 5 - running loss: 4.467\n",
            "\n",
            "Epoch: 0 - step: 6 - running loss: 4.345\n",
            "\n",
            "Epoch: 0 - step: 7 - running loss: 4.299\n",
            "\n",
            "Epoch: 0 - step: 8 - running loss: 4.196\n",
            "\n",
            "Epoch: 0 - step: 9 - running loss: 4.132\n",
            "\n",
            "Epoch: 0 - step: 10 - running loss: 4.128\n",
            "\n",
            "Epoch: 0 - step: 11 - running loss: 4.144\n",
            "\n",
            "Epoch: 0 - step: 12 - running loss: 4.129\n",
            "\n",
            "Epoch: 0 - step: 13 - running loss: 4.082\n",
            "\n",
            "Epoch: 0 - step: 14 - running loss: 4.060\n",
            "\n",
            "Epoch: 0 - step: 15 - running loss: 4.023\n",
            "\n",
            "Epoch: 0 - step: 16 - running loss: 4.020\n",
            "\n",
            "Epoch: 0 - step: 17 - running loss: 3.965\n",
            "\n",
            "Epoch: 0 - step: 18 - running loss: 3.946\n",
            "\n",
            "Epoch: 0 - step: 19 - running loss: 3.982\n",
            "\n",
            "Epoch: 0 - step: 20 - running loss: 3.973\n",
            "\n",
            "Epoch: 0 - step: 21 - running loss: 3.921\n",
            "\n",
            "Epoch: 0 - step: 22 - running loss: 3.888\n",
            "\n",
            "Epoch: 0 - step: 23 - running loss: 3.810\n",
            "\n",
            "Epoch: 0 - step: 24 - running loss: 3.800\n",
            "\n",
            "Epoch: 0 - step: 25 - running loss: 3.832\n",
            "\n",
            "Epoch: 0 - step: 26 - running loss: 3.862\n",
            "\n",
            "Epoch: 0 - step: 27 - running loss: 3.892\n",
            "\n",
            "Epoch: 0 - step: 28 - running loss: 3.814\n",
            "\n",
            "Epoch: 0 - step: 29 - running loss: 3.730\n",
            "\n",
            "Epoch: 0 - step: 30 - running loss: 3.673\n",
            "\n",
            "Epoch: 0 - step: 31 - running loss: 3.738\n",
            "Epoch 1/10 - Training Loss: 4.0967 - Validation Loss: 81.3620\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|         | 1/10 [03:01<27:13, 181.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 0\n",
            "\n",
            "\n",
            "Epoch: 1 - step: 1 - running loss: 3.824\n",
            "\n",
            "Epoch: 1 - step: 2 - running loss: 3.833\n",
            "\n",
            "Epoch: 1 - step: 3 - running loss: 3.854\n",
            "\n",
            "Epoch: 1 - step: 4 - running loss: 3.855\n",
            "\n",
            "Epoch: 1 - step: 5 - running loss: 3.861\n",
            "\n",
            "Epoch: 1 - step: 6 - running loss: 3.828\n",
            "\n",
            "Epoch: 1 - step: 7 - running loss: 3.824\n",
            "\n",
            "Epoch: 1 - step: 8 - running loss: 3.803\n",
            "\n",
            "Epoch: 1 - step: 9 - running loss: 3.808\n",
            "\n",
            "Epoch: 1 - step: 10 - running loss: 3.825\n",
            "\n",
            "Epoch: 1 - step: 11 - running loss: 3.849\n",
            "\n",
            "Epoch: 1 - step: 12 - running loss: 3.834\n",
            "\n",
            "Epoch: 1 - step: 13 - running loss: 3.834\n",
            "\n",
            "Epoch: 1 - step: 14 - running loss: 3.827\n",
            "\n",
            "Epoch: 1 - step: 15 - running loss: 3.807\n",
            "\n",
            "Epoch: 1 - step: 16 - running loss: 3.938\n",
            "\n",
            "Epoch: 1 - step: 17 - running loss: 3.693\n",
            "\n",
            "Epoch: 1 - step: 18 - running loss: 3.678\n",
            "\n",
            "Epoch: 1 - step: 19 - running loss: 3.744\n",
            "\n",
            "Epoch: 1 - step: 20 - running loss: 3.816\n",
            "\n",
            "Epoch: 1 - step: 21 - running loss: 3.889\n",
            "\n",
            "Epoch: 1 - step: 22 - running loss: 3.916\n",
            "\n",
            "Epoch: 1 - step: 23 - running loss: 3.890\n",
            "\n",
            "Epoch: 1 - step: 24 - running loss: 3.874\n",
            "\n",
            "Epoch: 1 - step: 25 - running loss: 3.832\n",
            "\n",
            "Epoch: 1 - step: 26 - running loss: 3.770\n",
            "\n",
            "Epoch: 1 - step: 27 - running loss: 3.780\n",
            "\n",
            "Epoch: 1 - step: 28 - running loss: 3.722\n",
            "\n",
            "Epoch: 1 - step: 29 - running loss: 3.753\n",
            "\n",
            "Epoch: 1 - step: 30 - running loss: 3.759\n",
            "\n",
            "Epoch: 1 - step: 31 - running loss: 3.786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|        | 2/10 [04:33<17:10, 128.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 - Training Loss: 3.8162 - Validation Loss: 42.0866\n",
            "====================================================================================================\n",
            "Centers updated - Step : 1\n",
            "\n",
            "\n",
            "Epoch: 2 - step: 1 - running loss: 3.804\n",
            "\n",
            "Epoch: 2 - step: 2 - running loss: 3.857\n",
            "\n",
            "Epoch: 2 - step: 3 - running loss: 3.878\n",
            "\n",
            "Epoch: 2 - step: 4 - running loss: 3.726\n",
            "\n",
            "Epoch: 2 - step: 5 - running loss: 3.667\n",
            "\n",
            "Epoch: 2 - step: 6 - running loss: 3.658\n",
            "\n",
            "Epoch: 2 - step: 7 - running loss: 3.636\n",
            "\n",
            "Epoch: 2 - step: 8 - running loss: 3.662\n",
            "\n",
            "Epoch: 2 - step: 9 - running loss: 3.702\n",
            "\n",
            "Epoch: 2 - step: 10 - running loss: 3.671\n",
            "\n",
            "Epoch: 2 - step: 11 - running loss: 3.692\n",
            "\n",
            "Epoch: 2 - step: 12 - running loss: 3.697\n",
            "\n",
            "Epoch: 2 - step: 13 - running loss: 3.699\n",
            "\n",
            "Epoch: 2 - step: 14 - running loss: 3.651\n",
            "\n",
            "Epoch: 2 - step: 15 - running loss: 3.678\n",
            "\n",
            "Epoch: 2 - step: 16 - running loss: 3.646\n",
            "\n",
            "Epoch: 2 - step: 17 - running loss: 3.599\n",
            "\n",
            "Epoch: 2 - step: 18 - running loss: 3.635\n",
            "\n",
            "Epoch: 2 - step: 19 - running loss: 3.623\n",
            "\n",
            "Epoch: 2 - step: 20 - running loss: 3.581\n",
            "\n",
            "Epoch: 2 - step: 21 - running loss: 3.601\n",
            "\n",
            "Epoch: 2 - step: 22 - running loss: 3.618\n",
            "\n",
            "Epoch: 2 - step: 23 - running loss: 3.595\n",
            "\n",
            "Epoch: 2 - step: 24 - running loss: 3.616\n",
            "\n",
            "Epoch: 2 - step: 25 - running loss: 3.620\n",
            "\n",
            "Epoch: 2 - step: 26 - running loss: 3.607\n",
            "\n",
            "Epoch: 2 - step: 27 - running loss: 3.613\n",
            "\n",
            "Epoch: 2 - step: 28 - running loss: 3.577\n",
            "\n",
            "Epoch: 2 - step: 29 - running loss: 3.596\n",
            "\n",
            "Epoch: 2 - step: 30 - running loss: 3.564\n",
            "\n",
            "Epoch: 2 - step: 31 - running loss: 3.560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|       | 3/10 [06:04<13:00, 111.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 - Training Loss: 3.6558 - Validation Loss: 96.9625\n",
            "====================================================================================================\n",
            "Centers updated - Step : 2\n",
            "\n",
            "\n",
            "Epoch: 3 - step: 1 - running loss: 3.560\n",
            "\n",
            "Epoch: 3 - step: 2 - running loss: 3.537\n",
            "\n",
            "Epoch: 3 - step: 3 - running loss: 3.560\n",
            "\n",
            "Epoch: 3 - step: 4 - running loss: 3.537\n",
            "\n",
            "Epoch: 3 - step: 5 - running loss: 3.547\n",
            "\n",
            "Epoch: 3 - step: 6 - running loss: 3.519\n",
            "\n",
            "Epoch: 3 - step: 7 - running loss: 3.485\n",
            "\n",
            "Epoch: 3 - step: 8 - running loss: 3.471\n",
            "\n",
            "Epoch: 3 - step: 9 - running loss: 3.498\n",
            "\n",
            "Epoch: 3 - step: 10 - running loss: 3.457\n",
            "\n",
            "Epoch: 3 - step: 11 - running loss: 3.471\n",
            "\n",
            "Epoch: 3 - step: 12 - running loss: 3.480\n",
            "\n",
            "Epoch: 3 - step: 13 - running loss: 3.447\n",
            "\n",
            "Epoch: 3 - step: 14 - running loss: 3.448\n",
            "\n",
            "Epoch: 3 - step: 15 - running loss: 3.423\n",
            "\n",
            "Epoch: 3 - step: 16 - running loss: 3.439\n",
            "\n",
            "Epoch: 3 - step: 17 - running loss: 3.436\n",
            "\n",
            "Epoch: 3 - step: 18 - running loss: 3.447\n",
            "\n",
            "Epoch: 3 - step: 19 - running loss: 3.426\n",
            "\n",
            "Epoch: 3 - step: 20 - running loss: 3.420\n",
            "\n",
            "Epoch: 3 - step: 21 - running loss: 3.432\n",
            "\n",
            "Epoch: 3 - step: 22 - running loss: 3.410\n",
            "\n",
            "Epoch: 3 - step: 23 - running loss: 3.389\n",
            "\n",
            "Epoch: 3 - step: 24 - running loss: 3.392\n",
            "\n",
            "Epoch: 3 - step: 25 - running loss: 3.406\n",
            "\n",
            "Epoch: 3 - step: 26 - running loss: 3.384\n",
            "\n",
            "Epoch: 3 - step: 27 - running loss: 3.404\n",
            "\n",
            "Epoch: 3 - step: 28 - running loss: 3.360\n",
            "\n",
            "Epoch: 3 - step: 29 - running loss: 3.403\n",
            "\n",
            "Epoch: 3 - step: 30 - running loss: 3.376\n",
            "\n",
            "Epoch: 3 - step: 31 - running loss: 3.394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|      | 4/10 [07:37<10:25, 104.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 - Training Loss: 3.4503 - Validation Loss: 123.1928\n",
            "====================================================================================================\n",
            "Centers updated - Step : 3\n",
            "\n",
            "\n",
            "Epoch: 4 - step: 1 - running loss: 3.379\n",
            "\n",
            "Epoch: 4 - step: 2 - running loss: 3.397\n",
            "\n",
            "Epoch: 4 - step: 3 - running loss: 3.412\n",
            "\n",
            "Epoch: 4 - step: 4 - running loss: 3.366\n",
            "\n",
            "Epoch: 4 - step: 5 - running loss: 3.350\n",
            "\n",
            "Epoch: 4 - step: 6 - running loss: 3.330\n",
            "\n",
            "Epoch: 4 - step: 7 - running loss: 3.351\n",
            "\n",
            "Epoch: 4 - step: 8 - running loss: 3.336\n",
            "\n",
            "Epoch: 4 - step: 9 - running loss: 3.329\n",
            "\n",
            "Epoch: 4 - step: 10 - running loss: 3.348\n",
            "\n",
            "Epoch: 4 - step: 11 - running loss: 3.317\n",
            "\n",
            "Epoch: 4 - step: 12 - running loss: 3.328\n",
            "\n",
            "Epoch: 4 - step: 13 - running loss: 3.341\n",
            "\n",
            "Epoch: 4 - step: 14 - running loss: 3.311\n",
            "\n",
            "Epoch: 4 - step: 15 - running loss: 3.358\n",
            "\n",
            "Epoch: 4 - step: 16 - running loss: 3.308\n",
            "\n",
            "Epoch: 4 - step: 17 - running loss: 3.295\n",
            "\n",
            "Epoch: 4 - step: 18 - running loss: 3.287\n",
            "\n",
            "Epoch: 4 - step: 19 - running loss: 3.283\n",
            "\n",
            "Epoch: 4 - step: 20 - running loss: 3.322\n",
            "\n",
            "Epoch: 4 - step: 21 - running loss: 3.319\n",
            "\n",
            "Epoch: 4 - step: 22 - running loss: 3.294\n",
            "\n",
            "Epoch: 4 - step: 23 - running loss: 3.286\n",
            "\n",
            "Epoch: 4 - step: 24 - running loss: 3.299\n",
            "\n",
            "Epoch: 4 - step: 25 - running loss: 3.258\n",
            "\n",
            "Epoch: 4 - step: 26 - running loss: 3.277\n",
            "\n",
            "Epoch: 4 - step: 27 - running loss: 3.258\n",
            "\n",
            "Epoch: 4 - step: 28 - running loss: 3.265\n",
            "\n",
            "Epoch: 4 - step: 29 - running loss: 3.272\n",
            "\n",
            "Epoch: 4 - step: 30 - running loss: 3.251\n",
            "\n",
            "Epoch: 4 - step: 31 - running loss: 3.237\n",
            "Epoch 5/10 - Training Loss: 3.3150 - Validation Loss: 91.2903\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|     | 5/10 [09:08<08:18, 99.60s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 4\n",
            "\n",
            "\n",
            "Epoch: 5 - step: 1 - running loss: 3.236\n",
            "\n",
            "Epoch: 5 - step: 3 - running loss: 3.209\n",
            "\n",
            "Epoch: 5 - step: 4 - running loss: 3.196\n",
            "\n",
            "Epoch: 5 - step: 5 - running loss: 3.213\n",
            "\n",
            "Epoch: 5 - step: 6 - running loss: 3.202\n",
            "\n",
            "Epoch: 5 - step: 7 - running loss: 3.192\n",
            "\n",
            "Epoch: 5 - step: 8 - running loss: 3.205\n",
            "\n",
            "Epoch: 5 - step: 9 - running loss: 3.202\n",
            "\n",
            "Epoch: 5 - step: 10 - running loss: 3.177\n",
            "\n",
            "Epoch: 5 - step: 11 - running loss: 3.181\n",
            "\n",
            "Epoch: 5 - step: 12 - running loss: 3.174\n",
            "\n",
            "Epoch: 5 - step: 13 - running loss: 3.164\n",
            "\n",
            "Epoch: 5 - step: 14 - running loss: 3.172\n",
            "\n",
            "Epoch: 5 - step: 15 - running loss: 3.137\n",
            "\n",
            "Epoch: 5 - step: 16 - running loss: 3.145\n",
            "\n",
            "Epoch: 5 - step: 17 - running loss: 3.174\n",
            "\n",
            "Epoch: 5 - step: 18 - running loss: 3.146\n",
            "\n",
            "Epoch: 5 - step: 19 - running loss: 3.147\n",
            "\n",
            "Epoch: 5 - step: 20 - running loss: 3.141\n",
            "\n",
            "Epoch: 5 - step: 21 - running loss: 3.132\n",
            "\n",
            "Epoch: 5 - step: 22 - running loss: 3.153\n",
            "\n",
            "Epoch: 5 - step: 23 - running loss: 3.136\n",
            "\n",
            "Epoch: 5 - step: 24 - running loss: 3.130\n",
            "\n",
            "Epoch: 5 - step: 25 - running loss: 3.122\n",
            "\n",
            "Epoch: 5 - step: 26 - running loss: 3.107\n",
            "\n",
            "Epoch: 5 - step: 27 - running loss: 3.139\n",
            "\n",
            "Epoch: 5 - step: 28 - running loss: 3.108\n",
            "\n",
            "Epoch: 5 - step: 29 - running loss: 3.099\n",
            "\n",
            "Epoch: 5 - step: 30 - running loss: 3.095\n",
            "\n",
            "Epoch: 5 - step: 31 - running loss: 3.082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|    | 6/10 [10:40<06:27, 96.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 - Training Loss: 3.1592 - Validation Loss: 84.5804\n",
            "====================================================================================================\n",
            "Centers updated - Step : 5\n",
            "\n",
            "\n",
            "Epoch: 6 - step: 1 - running loss: 3.069\n",
            "\n",
            "Epoch: 6 - step: 2 - running loss: 3.088\n",
            "\n",
            "Epoch: 6 - step: 3 - running loss: 3.072\n",
            "\n",
            "Epoch: 6 - step: 4 - running loss: 3.058\n",
            "\n",
            "Epoch: 6 - step: 5 - running loss: 3.085\n",
            "\n",
            "Epoch: 6 - step: 6 - running loss: 3.072\n",
            "\n",
            "Epoch: 6 - step: 7 - running loss: 3.056\n",
            "\n",
            "Epoch: 6 - step: 8 - running loss: 3.048\n",
            "\n",
            "Epoch: 6 - step: 9 - running loss: 3.045\n",
            "\n",
            "Epoch: 6 - step: 10 - running loss: 3.039\n",
            "\n",
            "Epoch: 6 - step: 11 - running loss: 3.013\n",
            "\n",
            "Epoch: 6 - step: 12 - running loss: 3.020\n",
            "\n",
            "Epoch: 6 - step: 13 - running loss: 3.040\n",
            "\n",
            "Epoch: 6 - step: 14 - running loss: 3.034\n",
            "\n",
            "Epoch: 6 - step: 15 - running loss: 3.014\n",
            "\n",
            "Epoch: 6 - step: 16 - running loss: 2.984\n",
            "\n",
            "Epoch: 6 - step: 17 - running loss: 3.024\n",
            "\n",
            "Epoch: 6 - step: 18 - running loss: 3.008\n",
            "\n",
            "Epoch: 6 - step: 19 - running loss: 2.995\n",
            "\n",
            "Epoch: 6 - step: 20 - running loss: 3.000\n",
            "\n",
            "Epoch: 6 - step: 21 - running loss: 2.994\n",
            "\n",
            "Epoch: 6 - step: 22 - running loss: 2.986\n",
            "\n",
            "Epoch: 6 - step: 23 - running loss: 2.982\n",
            "\n",
            "Epoch: 6 - step: 24 - running loss: 2.974\n",
            "\n",
            "Epoch: 6 - step: 25 - running loss: 2.988\n",
            "\n",
            "Epoch: 6 - step: 26 - running loss: 3.000\n",
            "\n",
            "Epoch: 6 - step: 27 - running loss: 2.964\n",
            "\n",
            "Epoch: 6 - step: 28 - running loss: 2.954\n",
            "\n",
            "Epoch: 6 - step: 29 - running loss: 2.939\n",
            "\n",
            "Epoch: 6 - step: 30 - running loss: 2.934\n",
            "\n",
            "Epoch: 6 - step: 31 - running loss: 2.926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|   | 7/10 [12:09<04:43, 94.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 - Training Loss: 3.0130 - Validation Loss: 103.2355\n",
            "====================================================================================================\n",
            "Centers updated - Step : 6\n",
            "\n",
            "\n",
            "Epoch: 7 - step: 1 - running loss: 2.907\n",
            "\n",
            "Epoch: 7 - step: 2 - running loss: 2.942\n",
            "\n",
            "Epoch: 7 - step: 3 - running loss: 2.897\n",
            "\n",
            "Epoch: 7 - step: 4 - running loss: 2.910\n",
            "\n",
            "Epoch: 7 - step: 5 - running loss: 2.924\n",
            "\n",
            "Epoch: 7 - step: 6 - running loss: 2.933\n",
            "\n",
            "Epoch: 7 - step: 7 - running loss: 2.909\n",
            "\n",
            "Epoch: 7 - step: 8 - running loss: 2.909\n",
            "\n",
            "Epoch: 7 - step: 9 - running loss: 2.897\n",
            "\n",
            "Epoch: 7 - step: 10 - running loss: 2.857\n",
            "\n",
            "Epoch: 7 - step: 11 - running loss: 2.878\n",
            "\n",
            "Epoch: 7 - step: 12 - running loss: 2.872\n",
            "\n",
            "Epoch: 7 - step: 13 - running loss: 2.867\n",
            "\n",
            "Epoch: 7 - step: 14 - running loss: 2.892\n",
            "\n",
            "Epoch: 7 - step: 15 - running loss: 2.862\n",
            "\n",
            "Epoch: 7 - step: 16 - running loss: 2.874\n",
            "\n",
            "Epoch: 7 - step: 17 - running loss: 2.853\n",
            "\n",
            "Epoch: 7 - step: 18 - running loss: 2.866\n",
            "\n",
            "Epoch: 7 - step: 19 - running loss: 2.854\n",
            "\n",
            "Epoch: 7 - step: 20 - running loss: 2.831\n",
            "\n",
            "Epoch: 7 - step: 21 - running loss: 2.831\n",
            "\n",
            "Epoch: 7 - step: 22 - running loss: 2.835\n",
            "\n",
            "Epoch: 7 - step: 23 - running loss: 2.824\n",
            "\n",
            "Epoch: 7 - step: 24 - running loss: 2.810\n",
            "\n",
            "Epoch: 7 - step: 25 - running loss: 2.819\n",
            "\n",
            "Epoch: 7 - step: 26 - running loss: 2.822\n",
            "\n",
            "Epoch: 7 - step: 27 - running loss: 2.816\n",
            "\n",
            "Epoch: 7 - step: 28 - running loss: 2.770\n",
            "\n",
            "Epoch: 7 - step: 29 - running loss: 2.806\n",
            "\n",
            "Epoch: 7 - step: 30 - running loss: 2.788\n",
            "\n",
            "Epoch: 7 - step: 31 - running loss: 2.771\n",
            "Epoch 8/10 - Training Loss: 2.8589 - Validation Loss: 90.1581\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|  | 8/10 [13:38<03:05, 92.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 7\n",
            "\n",
            "\n",
            "Epoch: 8 - step: 1 - running loss: 2.793\n",
            "\n",
            "Epoch: 8 - step: 2 - running loss: 2.781\n",
            "\n",
            "Epoch: 8 - step: 3 - running loss: 2.783\n",
            "\n",
            "Epoch: 8 - step: 4 - running loss: 2.779\n",
            "\n",
            "Epoch: 8 - step: 5 - running loss: 2.727\n",
            "\n",
            "Epoch: 8 - step: 6 - running loss: 2.771\n",
            "\n",
            "Epoch: 8 - step: 7 - running loss: 2.740\n",
            "\n",
            "Epoch: 8 - step: 8 - running loss: 2.759\n",
            "\n",
            "Epoch: 8 - step: 9 - running loss: 2.723\n",
            "\n",
            "Epoch: 8 - step: 10 - running loss: 2.722\n",
            "\n",
            "Epoch: 8 - step: 11 - running loss: 2.733\n",
            "\n",
            "Epoch: 8 - step: 12 - running loss: 2.754\n",
            "\n",
            "Epoch: 8 - step: 13 - running loss: 2.716\n",
            "\n",
            "Epoch: 8 - step: 14 - running loss: 2.700\n",
            "\n",
            "Epoch: 8 - step: 15 - running loss: 2.722\n",
            "\n",
            "Epoch: 8 - step: 16 - running loss: 2.719\n",
            "\n",
            "Epoch: 8 - step: 17 - running loss: 2.702\n",
            "\n",
            "Epoch: 8 - step: 18 - running loss: 2.683\n",
            "\n",
            "Epoch: 8 - step: 19 - running loss: 2.695\n",
            "\n",
            "Epoch: 8 - step: 20 - running loss: 2.699\n",
            "\n",
            "Epoch: 8 - step: 21 - running loss: 2.670\n",
            "\n",
            "Epoch: 8 - step: 22 - running loss: 2.685\n",
            "\n",
            "Epoch: 8 - step: 23 - running loss: 2.662\n",
            "\n",
            "Epoch: 8 - step: 24 - running loss: 2.704\n",
            "\n",
            "Epoch: 8 - step: 25 - running loss: 2.669\n",
            "\n",
            "Epoch: 8 - step: 26 - running loss: 2.630\n",
            "\n",
            "Epoch: 8 - step: 27 - running loss: 2.677\n",
            "\n",
            "Epoch: 8 - step: 28 - running loss: 2.646\n",
            "\n",
            "Epoch: 8 - step: 29 - running loss: 2.657\n",
            "\n",
            "Epoch: 8 - step: 30 - running loss: 2.645\n",
            "\n",
            "Epoch: 8 - step: 31 - running loss: 2.632\n",
            "Epoch 9/10 - Training Loss: 2.7089 - Validation Loss: 89.8372\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%| | 9/10 [15:08<01:31, 91.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centers updated - Step : 8\n",
            "\n",
            "\n",
            "Epoch: 9 - step: 1 - running loss: 2.631\n",
            "\n",
            "Epoch: 9 - step: 2 - running loss: 2.615\n",
            "\n",
            "Epoch: 9 - step: 3 - running loss: 2.622\n",
            "\n",
            "Epoch: 9 - step: 4 - running loss: 2.606\n",
            "\n",
            "Epoch: 9 - step: 5 - running loss: 2.606\n",
            "\n",
            "Epoch: 9 - step: 6 - running loss: 2.631\n",
            "\n",
            "Epoch: 9 - step: 7 - running loss: 2.786\n",
            "\n",
            "Epoch: 9 - step: 8 - running loss: 2.592\n",
            "\n",
            "Epoch: 9 - step: 9 - running loss: 2.703\n",
            "\n",
            "Epoch: 9 - step: 10 - running loss: 2.715\n",
            "\n",
            "Epoch: 9 - step: 11 - running loss: 2.734\n",
            "\n",
            "Epoch: 9 - step: 12 - running loss: 2.753\n",
            "\n",
            "Epoch: 9 - step: 13 - running loss: 2.713\n",
            "\n",
            "Epoch: 9 - step: 14 - running loss: 2.707\n",
            "\n",
            "Epoch: 9 - step: 15 - running loss: 2.661\n",
            "\n",
            "Epoch: 9 - step: 16 - running loss: 2.651\n",
            "\n",
            "Epoch: 9 - step: 17 - running loss: 2.648\n",
            "\n",
            "Epoch: 9 - step: 18 - running loss: 2.605\n",
            "\n",
            "Epoch: 9 - step: 19 - running loss: 2.602\n",
            "\n",
            "Epoch: 9 - step: 20 - running loss: 2.537\n",
            "\n",
            "Epoch: 9 - step: 21 - running loss: 2.491\n",
            "\n",
            "Epoch: 9 - step: 22 - running loss: 2.484\n",
            "\n",
            "Epoch: 9 - step: 23 - running loss: 2.510\n",
            "\n",
            "Epoch: 9 - step: 24 - running loss: 2.546\n",
            "\n",
            "Epoch: 9 - step: 25 - running loss: 2.571\n",
            "\n",
            "Epoch: 9 - step: 26 - running loss: 2.549\n",
            "\n",
            "Epoch: 9 - step: 27 - running loss: 2.505\n",
            "\n",
            "Epoch: 9 - step: 28 - running loss: 2.674\n",
            "\n",
            "Epoch: 9 - step: 29 - running loss: 2.462\n",
            "\n",
            "Epoch: 9 - step: 30 - running loss: 2.451\n",
            "\n",
            "Epoch: 9 - step: 31 - running loss: 2.521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 10/10 [16:36<00:00, 99.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 - Training Loss: 2.6091 - Validation Loss: 57.6644\n",
            "====================================================================================================\n",
            "Centers updated - Step : 9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sWkM0I4Oou66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQsaftUPou9S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}